{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arizzi/NNTutorial/blob/master/Tutorial3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxgS64DmqCrH",
        "colab_type": "text"
      },
      "source": [
        "## Import useful stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jO_-Tguu60O9",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input,Dense,Dropout\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "from math import *\n",
        "from matplotlib import pyplot as plt "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JcejQQHu8WQa"
      },
      "source": [
        "## Lets generate some data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LeVJ5UFW68Nf",
        "outputId": "ebe4e28e-fbcb-4ebc-b2d4-f1f79080f54e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "nsamples=3000\n",
        "\n",
        "def signalFeatures():\n",
        "  x=np.random.rand()*3\n",
        "  y=np.random.rand()*2\n",
        "  z=cos(x*y)\n",
        "  return x,y,z,1 #the last value here is the label, 1 = signal\n",
        "\n",
        "def backgroundFeatures():\n",
        "  x=np.random.normal(loc=1.5) #mean in 1.5\n",
        "  y=1/(abs(x)+1)+np.random.rand()*0.7\n",
        "  z=cos(x)\n",
        "  return x,y,z,0 #the last value here is the label, 0 = signal\n",
        "\n",
        "\n",
        "\n",
        "signal = np.asarray([signalFeatures() for x in range(nsamples)])\n",
        "background = np.asarray([backgroundFeatures() for x in range(nsamples)])\n",
        "\n",
        "print(\"Signal\")\n",
        "print(\"Shape is:\", signal.shape)\n",
        "print(signal)\n",
        "print(\"Signal one entry\")\n",
        "print(signal[0,:])\n",
        "print(\"Signal feature 2\")\n",
        "print(signal[:,2])\n",
        "print(\"Background\")\n",
        "print(background)\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Signal\n",
            "Shape is: (3000, 4)\n",
            "[[ 1.9847131   0.59469956  0.38064002  1.        ]\n",
            " [ 2.53972808  1.86722384  0.02984741  1.        ]\n",
            " [ 2.15278753  1.71862222 -0.84819089  1.        ]\n",
            " ...\n",
            " [ 2.07227324  1.31027081 -0.91047981  1.        ]\n",
            " [ 0.33257429  0.24665556  0.99663732  1.        ]\n",
            " [ 0.26339226  0.89501235  0.97234193  1.        ]]\n",
            "Signal one entry\n",
            "[1.9847131  0.59469956 0.38064002 1.        ]\n",
            "Signal feature 2\n",
            "[ 0.38064002  0.02984741 -0.84819089 ... -0.91047981  0.99663732\n",
            "  0.97234193]\n",
            "Background\n",
            "[[ 3.33263187  0.3551567  -0.98180744  0.        ]\n",
            " [ 2.30975396  0.72435369 -0.67351779  0.        ]\n",
            " [ 0.59397876  1.30193026  0.82872048  0.        ]\n",
            " ...\n",
            " [ 1.0786115   0.57650382  0.47255251  0.        ]\n",
            " [ 1.88838613  0.81894842 -0.31227781  0.        ]\n",
            " [ 2.20537749  0.79563242 -0.59284027  0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GJB3TadFBiNm"
      },
      "source": [
        "Let's look at our generated features for signal and background"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DXovE04P79Vw",
        "outputId": "ba9a1eec-8779-43d7-cac4-ff8973e11534",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "plt.hist(signal[:,1], bins = [ (x/20.-2.5) for x in range(100)]) \n",
        "plt.title(\"Feature2\") \n",
        "plt.hist(background[:,1], bins = [ (x/20.-2.5) for x in range(100)],alpha=.7) #make it a bit transparent \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W1ZXS7iqQby",
        "colab_type": "code",
        "outputId": "26a312c5-53dd-4ac4-9b7a-1c996f8ff13a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.plot(signal[0:100,0],signal[0:100,1],'*')\n",
        "plt.plot(background[0:100,0],background[0:100,1],'*')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa67c5fb630>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MN1px9PfBp9y",
        "outputId": "57f655f4-93fc-47a5-fc41-133510a8eec2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "data=np.concatenate((background,signal))\n",
        "np.random.shuffle(data)\n",
        "print(data)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.55680821  0.89606879  0.84894623  0.        ]\n",
            " [ 1.32672393  0.59897894  0.24165631  0.        ]\n",
            " [ 0.88206423  1.17920496  0.6355588   0.        ]\n",
            " ...\n",
            " [ 0.84870544  0.33578793  0.95966586  1.        ]\n",
            " [ 1.81551756  0.61701495 -0.24228588  0.        ]\n",
            " [ 1.96474401  0.02223957  0.99904552  1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3NibVPZhC3hL"
      },
      "source": [
        "Now we build a Feed Forward NN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KRMhsQ2nC6oa",
        "outputId": "169171bd-31ee-451b-91f7-1a7e82e315d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17462
        }
      },
      "source": [
        "inputs=Input(shape=(3,))\n",
        "h1=  Dense(10, activation='relu')(inputs)\n",
        "h1d= Dropout(0.1)(h1)\n",
        "h2=  Dense(10, activation='relu')(h1)\n",
        "h3=  Dense(5, activation='relu')(h2)\n",
        "outputs = Dense(1, activation='sigmoid')(h3)\n",
        "#h1=  Dense(10, activation='relu')(inputs)\n",
        "#outputs = Dense(1, activation='sigmoid')(h1)\n",
        "model = Model(input=inputs, output=outputs)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "history=model.fit(data[:,0:3],data[:,3:],validation_split=0.5,nb_epoch=500)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 3)                 0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                40        \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 5)                 55        \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 211\n",
            "Trainable params: 211\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 3000 samples, validate on 3000 samples\n",
            "Epoch 1/500\n",
            "3000/3000 [==============================] - 1s 177us/step - loss: 0.6891 - acc: 0.5383 - val_loss: 0.6609 - val_acc: 0.5777\n",
            "Epoch 2/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.6502 - acc: 0.6237 - val_loss: 0.6352 - val_acc: 0.6487\n",
            "Epoch 3/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.6194 - acc: 0.6650 - val_loss: 0.5944 - val_acc: 0.6717\n",
            "Epoch 4/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.5760 - acc: 0.6927 - val_loss: 0.5430 - val_acc: 0.7017\n",
            "Epoch 5/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.5139 - acc: 0.7433 - val_loss: 0.4714 - val_acc: 0.8063\n",
            "Epoch 6/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.4499 - acc: 0.8120 - val_loss: 0.4327 - val_acc: 0.7923\n",
            "Epoch 7/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.3985 - acc: 0.8407 - val_loss: 0.3646 - val_acc: 0.8710\n",
            "Epoch 8/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.3603 - acc: 0.8503 - val_loss: 0.3376 - val_acc: 0.8617\n",
            "Epoch 9/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.3300 - acc: 0.8650 - val_loss: 0.3060 - val_acc: 0.8787\n",
            "Epoch 10/500\n",
            "3000/3000 [==============================] - 0s 59us/step - loss: 0.3116 - acc: 0.8647 - val_loss: 0.2861 - val_acc: 0.8850\n",
            "Epoch 11/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.2952 - acc: 0.8717 - val_loss: 0.2759 - val_acc: 0.8807\n",
            "Epoch 12/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.2879 - acc: 0.8757 - val_loss: 0.2669 - val_acc: 0.8810\n",
            "Epoch 13/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.2751 - acc: 0.8773 - val_loss: 0.2584 - val_acc: 0.8943\n",
            "Epoch 14/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.2666 - acc: 0.8847 - val_loss: 0.2550 - val_acc: 0.8817\n",
            "Epoch 15/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.2599 - acc: 0.8800 - val_loss: 0.2433 - val_acc: 0.8977\n",
            "Epoch 16/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.2531 - acc: 0.8887 - val_loss: 0.2392 - val_acc: 0.8960\n",
            "Epoch 17/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.2487 - acc: 0.8833 - val_loss: 0.2333 - val_acc: 0.8983\n",
            "Epoch 18/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.2445 - acc: 0.8883 - val_loss: 0.2308 - val_acc: 0.8970\n",
            "Epoch 19/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.2412 - acc: 0.8913 - val_loss: 0.2281 - val_acc: 0.9043\n",
            "Epoch 20/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.2391 - acc: 0.8897 - val_loss: 0.2246 - val_acc: 0.9003\n",
            "Epoch 21/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.2401 - acc: 0.8930 - val_loss: 0.2207 - val_acc: 0.8990\n",
            "Epoch 22/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.2312 - acc: 0.8930 - val_loss: 0.2230 - val_acc: 0.8977\n",
            "Epoch 23/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.2301 - acc: 0.8970 - val_loss: 0.2162 - val_acc: 0.9010\n",
            "Epoch 24/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.2251 - acc: 0.9000 - val_loss: 0.2180 - val_acc: 0.8967\n",
            "Epoch 25/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.2268 - acc: 0.8973 - val_loss: 0.2131 - val_acc: 0.9027\n",
            "Epoch 26/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.2269 - acc: 0.9007 - val_loss: 0.2084 - val_acc: 0.9000\n",
            "Epoch 27/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.2213 - acc: 0.8997 - val_loss: 0.2081 - val_acc: 0.9030\n",
            "Epoch 28/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.2195 - acc: 0.9027 - val_loss: 0.2018 - val_acc: 0.9117\n",
            "Epoch 29/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.2199 - acc: 0.9033 - val_loss: 0.2020 - val_acc: 0.9093\n",
            "Epoch 30/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.2173 - acc: 0.9033 - val_loss: 0.2090 - val_acc: 0.9020\n",
            "Epoch 31/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.2176 - acc: 0.9040 - val_loss: 0.1996 - val_acc: 0.9073\n",
            "Epoch 32/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.2146 - acc: 0.9067 - val_loss: 0.2056 - val_acc: 0.9060\n",
            "Epoch 33/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.2139 - acc: 0.9067 - val_loss: 0.1959 - val_acc: 0.9147\n",
            "Epoch 34/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.2126 - acc: 0.9067 - val_loss: 0.1936 - val_acc: 0.9137\n",
            "Epoch 35/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.2092 - acc: 0.9080 - val_loss: 0.1945 - val_acc: 0.9087\n",
            "Epoch 36/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.2125 - acc: 0.9050 - val_loss: 0.1933 - val_acc: 0.9083\n",
            "Epoch 37/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.2088 - acc: 0.9060 - val_loss: 0.1964 - val_acc: 0.9037\n",
            "Epoch 38/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.2089 - acc: 0.9053 - val_loss: 0.1886 - val_acc: 0.9147\n",
            "Epoch 39/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.2048 - acc: 0.9093 - val_loss: 0.1908 - val_acc: 0.9100\n",
            "Epoch 40/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.2063 - acc: 0.9087 - val_loss: 0.1943 - val_acc: 0.9140\n",
            "Epoch 41/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.2080 - acc: 0.9037 - val_loss: 0.1950 - val_acc: 0.9110\n",
            "Epoch 42/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.2043 - acc: 0.9103 - val_loss: 0.1976 - val_acc: 0.9053\n",
            "Epoch 43/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.2071 - acc: 0.9047 - val_loss: 0.1873 - val_acc: 0.9113\n",
            "Epoch 44/500\n",
            "3000/3000 [==============================] - 0s 55us/step - loss: 0.1992 - acc: 0.9117 - val_loss: 0.1842 - val_acc: 0.9170\n",
            "Epoch 45/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.2050 - acc: 0.9080 - val_loss: 0.1960 - val_acc: 0.9083\n",
            "Epoch 46/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1984 - acc: 0.9113 - val_loss: 0.1860 - val_acc: 0.9140\n",
            "Epoch 47/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1985 - acc: 0.9120 - val_loss: 0.1844 - val_acc: 0.9170\n",
            "Epoch 48/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.2003 - acc: 0.9103 - val_loss: 0.1821 - val_acc: 0.9180\n",
            "Epoch 49/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.2014 - acc: 0.9137 - val_loss: 0.1954 - val_acc: 0.9097\n",
            "Epoch 50/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.2006 - acc: 0.9100 - val_loss: 0.1794 - val_acc: 0.9217\n",
            "Epoch 51/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1975 - acc: 0.9127 - val_loss: 0.1836 - val_acc: 0.9123\n",
            "Epoch 52/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1958 - acc: 0.9103 - val_loss: 0.1808 - val_acc: 0.9147\n",
            "Epoch 53/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1938 - acc: 0.9167 - val_loss: 0.1801 - val_acc: 0.9137\n",
            "Epoch 54/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1945 - acc: 0.9147 - val_loss: 0.1850 - val_acc: 0.9123\n",
            "Epoch 55/500\n",
            "3000/3000 [==============================] - 0s 50us/step - loss: 0.1958 - acc: 0.9080 - val_loss: 0.1887 - val_acc: 0.9080\n",
            "Epoch 56/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1944 - acc: 0.9127 - val_loss: 0.1742 - val_acc: 0.9220\n",
            "Epoch 57/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1929 - acc: 0.9153 - val_loss: 0.1760 - val_acc: 0.9200\n",
            "Epoch 58/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1908 - acc: 0.9187 - val_loss: 0.1742 - val_acc: 0.9180\n",
            "Epoch 59/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1905 - acc: 0.9173 - val_loss: 0.1737 - val_acc: 0.9187\n",
            "Epoch 60/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1895 - acc: 0.9160 - val_loss: 0.1782 - val_acc: 0.9207\n",
            "Epoch 61/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1882 - acc: 0.9150 - val_loss: 0.1730 - val_acc: 0.9170\n",
            "Epoch 62/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1894 - acc: 0.9160 - val_loss: 0.1705 - val_acc: 0.9240\n",
            "Epoch 63/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1896 - acc: 0.9153 - val_loss: 0.1779 - val_acc: 0.9107\n",
            "Epoch 64/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1861 - acc: 0.9147 - val_loss: 0.1804 - val_acc: 0.9180\n",
            "Epoch 65/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1873 - acc: 0.9150 - val_loss: 0.1679 - val_acc: 0.9230\n",
            "Epoch 66/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1853 - acc: 0.9150 - val_loss: 0.1800 - val_acc: 0.9147\n",
            "Epoch 67/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1845 - acc: 0.9173 - val_loss: 0.1699 - val_acc: 0.9183\n",
            "Epoch 68/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1833 - acc: 0.9173 - val_loss: 0.1802 - val_acc: 0.9120\n",
            "Epoch 69/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1826 - acc: 0.9180 - val_loss: 0.1675 - val_acc: 0.9200\n",
            "Epoch 70/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1828 - acc: 0.9157 - val_loss: 0.1797 - val_acc: 0.9190\n",
            "Epoch 71/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1828 - acc: 0.9183 - val_loss: 0.1820 - val_acc: 0.9113\n",
            "Epoch 72/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1856 - acc: 0.9170 - val_loss: 0.1637 - val_acc: 0.9277\n",
            "Epoch 73/500\n",
            "3000/3000 [==============================] - 0s 55us/step - loss: 0.1785 - acc: 0.9200 - val_loss: 0.1713 - val_acc: 0.9150\n",
            "Epoch 74/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1789 - acc: 0.9177 - val_loss: 0.1683 - val_acc: 0.9207\n",
            "Epoch 75/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1764 - acc: 0.9213 - val_loss: 0.1642 - val_acc: 0.9227\n",
            "Epoch 76/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1772 - acc: 0.9157 - val_loss: 0.1669 - val_acc: 0.9197\n",
            "Epoch 77/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1771 - acc: 0.9190 - val_loss: 0.1692 - val_acc: 0.9190\n",
            "Epoch 78/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1748 - acc: 0.9167 - val_loss: 0.1645 - val_acc: 0.9210\n",
            "Epoch 79/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1786 - acc: 0.9173 - val_loss: 0.1611 - val_acc: 0.9257\n",
            "Epoch 80/500\n",
            "3000/3000 [==============================] - 0s 57us/step - loss: 0.1743 - acc: 0.9177 - val_loss: 0.1608 - val_acc: 0.9220\n",
            "Epoch 81/500\n",
            "3000/3000 [==============================] - 0s 55us/step - loss: 0.1713 - acc: 0.9197 - val_loss: 0.1608 - val_acc: 0.9250\n",
            "Epoch 82/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1767 - acc: 0.9203 - val_loss: 0.1680 - val_acc: 0.9227\n",
            "Epoch 83/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1765 - acc: 0.9227 - val_loss: 0.1675 - val_acc: 0.9217\n",
            "Epoch 84/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1720 - acc: 0.9227 - val_loss: 0.1624 - val_acc: 0.9247\n",
            "Epoch 85/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1729 - acc: 0.9217 - val_loss: 0.1657 - val_acc: 0.9197\n",
            "Epoch 86/500\n",
            "3000/3000 [==============================] - 0s 55us/step - loss: 0.1712 - acc: 0.9243 - val_loss: 0.1653 - val_acc: 0.9187\n",
            "Epoch 87/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1701 - acc: 0.9237 - val_loss: 0.1573 - val_acc: 0.9280\n",
            "Epoch 88/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1710 - acc: 0.9227 - val_loss: 0.1663 - val_acc: 0.9210\n",
            "Epoch 89/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1705 - acc: 0.9177 - val_loss: 0.1603 - val_acc: 0.9230\n",
            "Epoch 90/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1718 - acc: 0.9203 - val_loss: 0.1657 - val_acc: 0.9197\n",
            "Epoch 91/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1760 - acc: 0.9193 - val_loss: 0.1625 - val_acc: 0.9253\n",
            "Epoch 92/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1708 - acc: 0.9220 - val_loss: 0.1591 - val_acc: 0.9227\n",
            "Epoch 93/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1674 - acc: 0.9220 - val_loss: 0.1559 - val_acc: 0.9300\n",
            "Epoch 94/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1730 - acc: 0.9177 - val_loss: 0.1560 - val_acc: 0.9250\n",
            "Epoch 95/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1686 - acc: 0.9207 - val_loss: 0.1595 - val_acc: 0.9233\n",
            "Epoch 96/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1709 - acc: 0.9217 - val_loss: 0.1634 - val_acc: 0.9203\n",
            "Epoch 97/500\n",
            "3000/3000 [==============================] - 0s 56us/step - loss: 0.1641 - acc: 0.9230 - val_loss: 0.1569 - val_acc: 0.9240\n",
            "Epoch 98/500\n",
            "3000/3000 [==============================] - 0s 56us/step - loss: 0.1654 - acc: 0.9203 - val_loss: 0.1625 - val_acc: 0.9230\n",
            "Epoch 99/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1652 - acc: 0.9243 - val_loss: 0.1638 - val_acc: 0.9243\n",
            "Epoch 100/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1678 - acc: 0.9230 - val_loss: 0.1566 - val_acc: 0.9240\n",
            "Epoch 101/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1627 - acc: 0.9207 - val_loss: 0.1735 - val_acc: 0.9163\n",
            "Epoch 102/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1629 - acc: 0.9233 - val_loss: 0.1550 - val_acc: 0.9270\n",
            "Epoch 103/500\n",
            "3000/3000 [==============================] - 0s 56us/step - loss: 0.1618 - acc: 0.9250 - val_loss: 0.1721 - val_acc: 0.9163\n",
            "Epoch 104/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1640 - acc: 0.9263 - val_loss: 0.1614 - val_acc: 0.9237\n",
            "Epoch 105/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1662 - acc: 0.9200 - val_loss: 0.1581 - val_acc: 0.9213\n",
            "Epoch 106/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1622 - acc: 0.9233 - val_loss: 0.1565 - val_acc: 0.9210\n",
            "Epoch 107/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1610 - acc: 0.9270 - val_loss: 0.1534 - val_acc: 0.9240\n",
            "Epoch 108/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1640 - acc: 0.9197 - val_loss: 0.1634 - val_acc: 0.9243\n",
            "Epoch 109/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1611 - acc: 0.9233 - val_loss: 0.1588 - val_acc: 0.9223\n",
            "Epoch 110/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1629 - acc: 0.9237 - val_loss: 0.1576 - val_acc: 0.9247\n",
            "Epoch 111/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1602 - acc: 0.9247 - val_loss: 0.1600 - val_acc: 0.9210\n",
            "Epoch 112/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1604 - acc: 0.9273 - val_loss: 0.1554 - val_acc: 0.9223\n",
            "Epoch 113/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1618 - acc: 0.9223 - val_loss: 0.1540 - val_acc: 0.9227\n",
            "Epoch 114/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1599 - acc: 0.9273 - val_loss: 0.1563 - val_acc: 0.9200\n",
            "Epoch 115/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1590 - acc: 0.9260 - val_loss: 0.1508 - val_acc: 0.9257\n",
            "Epoch 116/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1595 - acc: 0.9283 - val_loss: 0.1674 - val_acc: 0.9213\n",
            "Epoch 117/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1597 - acc: 0.9243 - val_loss: 0.1562 - val_acc: 0.9263\n",
            "Epoch 118/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1601 - acc: 0.9263 - val_loss: 0.1488 - val_acc: 0.9247\n",
            "Epoch 119/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1603 - acc: 0.9237 - val_loss: 0.1513 - val_acc: 0.9270\n",
            "Epoch 120/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1585 - acc: 0.9260 - val_loss: 0.1599 - val_acc: 0.9240\n",
            "Epoch 121/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1586 - acc: 0.9257 - val_loss: 0.1521 - val_acc: 0.9257\n",
            "Epoch 122/500\n",
            "3000/3000 [==============================] - 0s 55us/step - loss: 0.1562 - acc: 0.9307 - val_loss: 0.1629 - val_acc: 0.9250\n",
            "Epoch 123/500\n",
            "3000/3000 [==============================] - 0s 55us/step - loss: 0.1573 - acc: 0.9280 - val_loss: 0.1584 - val_acc: 0.9227\n",
            "Epoch 124/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1556 - acc: 0.9277 - val_loss: 0.1565 - val_acc: 0.9237\n",
            "Epoch 125/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1561 - acc: 0.9257 - val_loss: 0.1476 - val_acc: 0.9297\n",
            "Epoch 126/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1552 - acc: 0.9293 - val_loss: 0.1721 - val_acc: 0.9257\n",
            "Epoch 127/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1570 - acc: 0.9287 - val_loss: 0.1476 - val_acc: 0.9243\n",
            "Epoch 128/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1568 - acc: 0.9243 - val_loss: 0.1559 - val_acc: 0.9257\n",
            "Epoch 129/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1563 - acc: 0.9287 - val_loss: 0.1519 - val_acc: 0.9250\n",
            "Epoch 130/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1541 - acc: 0.9280 - val_loss: 0.1459 - val_acc: 0.9347\n",
            "Epoch 131/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1559 - acc: 0.9290 - val_loss: 0.1571 - val_acc: 0.9297\n",
            "Epoch 132/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1586 - acc: 0.9290 - val_loss: 0.1491 - val_acc: 0.9277\n",
            "Epoch 133/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1560 - acc: 0.9287 - val_loss: 0.1587 - val_acc: 0.9277\n",
            "Epoch 134/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1554 - acc: 0.9243 - val_loss: 0.1502 - val_acc: 0.9307\n",
            "Epoch 135/500\n",
            "3000/3000 [==============================] - 0s 57us/step - loss: 0.1542 - acc: 0.9277 - val_loss: 0.1463 - val_acc: 0.9277\n",
            "Epoch 136/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1554 - acc: 0.9263 - val_loss: 0.1453 - val_acc: 0.9267\n",
            "Epoch 137/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1562 - acc: 0.9283 - val_loss: 0.1546 - val_acc: 0.9200\n",
            "Epoch 138/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1611 - acc: 0.9237 - val_loss: 0.1666 - val_acc: 0.9277\n",
            "Epoch 139/500\n",
            "3000/3000 [==============================] - 0s 55us/step - loss: 0.1576 - acc: 0.9277 - val_loss: 0.1652 - val_acc: 0.9207\n",
            "Epoch 140/500\n",
            "3000/3000 [==============================] - 0s 58us/step - loss: 0.1575 - acc: 0.9283 - val_loss: 0.1487 - val_acc: 0.9230\n",
            "Epoch 141/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1529 - acc: 0.9253 - val_loss: 0.1559 - val_acc: 0.9290\n",
            "Epoch 142/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1588 - acc: 0.9253 - val_loss: 0.1460 - val_acc: 0.9300\n",
            "Epoch 143/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1595 - acc: 0.9303 - val_loss: 0.1472 - val_acc: 0.9283\n",
            "Epoch 144/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1518 - acc: 0.9333 - val_loss: 0.1447 - val_acc: 0.9277\n",
            "Epoch 145/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1531 - acc: 0.9270 - val_loss: 0.1690 - val_acc: 0.9180\n",
            "Epoch 146/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1581 - acc: 0.9280 - val_loss: 0.1440 - val_acc: 0.9280\n",
            "Epoch 147/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1566 - acc: 0.9280 - val_loss: 0.1464 - val_acc: 0.9307\n",
            "Epoch 148/500\n",
            "3000/3000 [==============================] - 0s 57us/step - loss: 0.1559 - acc: 0.9317 - val_loss: 0.1449 - val_acc: 0.9270\n",
            "Epoch 149/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1556 - acc: 0.9297 - val_loss: 0.1464 - val_acc: 0.9253\n",
            "Epoch 150/500\n",
            "3000/3000 [==============================] - 0s 55us/step - loss: 0.1515 - acc: 0.9330 - val_loss: 0.1502 - val_acc: 0.9247\n",
            "Epoch 151/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1552 - acc: 0.9290 - val_loss: 0.1516 - val_acc: 0.9323\n",
            "Epoch 152/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1503 - acc: 0.9293 - val_loss: 0.1451 - val_acc: 0.9280\n",
            "Epoch 153/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1488 - acc: 0.9313 - val_loss: 0.1432 - val_acc: 0.9300\n",
            "Epoch 154/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1511 - acc: 0.9277 - val_loss: 0.1425 - val_acc: 0.9300\n",
            "Epoch 155/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1519 - acc: 0.9293 - val_loss: 0.1459 - val_acc: 0.9257\n",
            "Epoch 156/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1514 - acc: 0.9287 - val_loss: 0.1475 - val_acc: 0.9287\n",
            "Epoch 157/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1511 - acc: 0.9303 - val_loss: 0.1481 - val_acc: 0.9323\n",
            "Epoch 158/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1516 - acc: 0.9287 - val_loss: 0.1456 - val_acc: 0.9300\n",
            "Epoch 159/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1489 - acc: 0.9330 - val_loss: 0.1423 - val_acc: 0.9290\n",
            "Epoch 160/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1523 - acc: 0.9290 - val_loss: 0.1444 - val_acc: 0.9270\n",
            "Epoch 161/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1505 - acc: 0.9287 - val_loss: 0.1586 - val_acc: 0.9223\n",
            "Epoch 162/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1512 - acc: 0.9267 - val_loss: 0.1521 - val_acc: 0.9280\n",
            "Epoch 163/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1555 - acc: 0.9283 - val_loss: 0.1446 - val_acc: 0.9307\n",
            "Epoch 164/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1479 - acc: 0.9290 - val_loss: 0.1479 - val_acc: 0.9310\n",
            "Epoch 165/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1506 - acc: 0.9293 - val_loss: 0.1455 - val_acc: 0.9267\n",
            "Epoch 166/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1496 - acc: 0.9300 - val_loss: 0.1509 - val_acc: 0.9313\n",
            "Epoch 167/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1498 - acc: 0.9330 - val_loss: 0.1476 - val_acc: 0.9280\n",
            "Epoch 168/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1491 - acc: 0.9313 - val_loss: 0.1487 - val_acc: 0.9357\n",
            "Epoch 169/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1482 - acc: 0.9317 - val_loss: 0.1451 - val_acc: 0.9320\n",
            "Epoch 170/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1476 - acc: 0.9330 - val_loss: 0.1382 - val_acc: 0.9330\n",
            "Epoch 171/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1485 - acc: 0.9280 - val_loss: 0.1718 - val_acc: 0.9277\n",
            "Epoch 172/500\n",
            "3000/3000 [==============================] - 0s 55us/step - loss: 0.1478 - acc: 0.9313 - val_loss: 0.1470 - val_acc: 0.9300\n",
            "Epoch 173/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1540 - acc: 0.9287 - val_loss: 0.1529 - val_acc: 0.9330\n",
            "Epoch 174/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1476 - acc: 0.9330 - val_loss: 0.1447 - val_acc: 0.9283\n",
            "Epoch 175/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1470 - acc: 0.9320 - val_loss: 0.1440 - val_acc: 0.9327\n",
            "Epoch 176/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1503 - acc: 0.9273 - val_loss: 0.1482 - val_acc: 0.9263\n",
            "Epoch 177/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1521 - acc: 0.9277 - val_loss: 0.1425 - val_acc: 0.9283\n",
            "Epoch 178/500\n",
            "3000/3000 [==============================] - 0s 55us/step - loss: 0.1477 - acc: 0.9303 - val_loss: 0.1434 - val_acc: 0.9317\n",
            "Epoch 179/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1496 - acc: 0.9273 - val_loss: 0.1469 - val_acc: 0.9287\n",
            "Epoch 180/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1478 - acc: 0.9333 - val_loss: 0.1412 - val_acc: 0.9300\n",
            "Epoch 181/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1520 - acc: 0.9303 - val_loss: 0.1398 - val_acc: 0.9273\n",
            "Epoch 182/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1485 - acc: 0.9303 - val_loss: 0.1395 - val_acc: 0.9313\n",
            "Epoch 183/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1497 - acc: 0.9273 - val_loss: 0.1543 - val_acc: 0.9360\n",
            "Epoch 184/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1473 - acc: 0.9300 - val_loss: 0.1404 - val_acc: 0.9317\n",
            "Epoch 185/500\n",
            "3000/3000 [==============================] - 0s 56us/step - loss: 0.1430 - acc: 0.9317 - val_loss: 0.1604 - val_acc: 0.9233\n",
            "Epoch 186/500\n",
            "3000/3000 [==============================] - 0s 50us/step - loss: 0.1511 - acc: 0.9277 - val_loss: 0.1408 - val_acc: 0.9300\n",
            "Epoch 187/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1503 - acc: 0.9337 - val_loss: 0.1386 - val_acc: 0.9323\n",
            "Epoch 188/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1475 - acc: 0.9290 - val_loss: 0.1381 - val_acc: 0.9297\n",
            "Epoch 189/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1454 - acc: 0.9333 - val_loss: 0.1424 - val_acc: 0.9343\n",
            "Epoch 190/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1446 - acc: 0.9353 - val_loss: 0.1569 - val_acc: 0.9327\n",
            "Epoch 191/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1471 - acc: 0.9330 - val_loss: 0.1461 - val_acc: 0.9340\n",
            "Epoch 192/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1440 - acc: 0.9340 - val_loss: 0.1397 - val_acc: 0.9317\n",
            "Epoch 193/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1465 - acc: 0.9337 - val_loss: 0.1817 - val_acc: 0.9173\n",
            "Epoch 194/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1474 - acc: 0.9327 - val_loss: 0.1365 - val_acc: 0.9380\n",
            "Epoch 195/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1442 - acc: 0.9360 - val_loss: 0.1395 - val_acc: 0.9317\n",
            "Epoch 196/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1480 - acc: 0.9310 - val_loss: 0.1400 - val_acc: 0.9340\n",
            "Epoch 197/500\n",
            "3000/3000 [==============================] - 0s 55us/step - loss: 0.1456 - acc: 0.9370 - val_loss: 0.1498 - val_acc: 0.9363\n",
            "Epoch 198/500\n",
            "3000/3000 [==============================] - 0s 55us/step - loss: 0.1442 - acc: 0.9350 - val_loss: 0.1403 - val_acc: 0.9290\n",
            "Epoch 199/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1475 - acc: 0.9310 - val_loss: 0.1456 - val_acc: 0.9293\n",
            "Epoch 200/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1419 - acc: 0.9367 - val_loss: 0.1378 - val_acc: 0.9320\n",
            "Epoch 201/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1447 - acc: 0.9313 - val_loss: 0.1415 - val_acc: 0.9330\n",
            "Epoch 202/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1461 - acc: 0.9343 - val_loss: 0.1524 - val_acc: 0.9340\n",
            "Epoch 203/500\n",
            "3000/3000 [==============================] - 0s 61us/step - loss: 0.1439 - acc: 0.9337 - val_loss: 0.1375 - val_acc: 0.9280\n",
            "Epoch 204/500\n",
            "3000/3000 [==============================] - 0s 55us/step - loss: 0.1444 - acc: 0.9290 - val_loss: 0.1401 - val_acc: 0.9337\n",
            "Epoch 205/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1461 - acc: 0.9300 - val_loss: 0.1363 - val_acc: 0.9327\n",
            "Epoch 206/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1447 - acc: 0.9323 - val_loss: 0.1500 - val_acc: 0.9267\n",
            "Epoch 207/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1445 - acc: 0.9310 - val_loss: 0.1364 - val_acc: 0.9307\n",
            "Epoch 208/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1409 - acc: 0.9343 - val_loss: 0.1413 - val_acc: 0.9307\n",
            "Epoch 209/500\n",
            "3000/3000 [==============================] - 0s 56us/step - loss: 0.1418 - acc: 0.9350 - val_loss: 0.1412 - val_acc: 0.9320\n",
            "Epoch 210/500\n",
            "3000/3000 [==============================] - 0s 55us/step - loss: 0.1431 - acc: 0.9340 - val_loss: 0.1395 - val_acc: 0.9287\n",
            "Epoch 211/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1434 - acc: 0.9353 - val_loss: 0.1357 - val_acc: 0.9377\n",
            "Epoch 212/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1428 - acc: 0.9337 - val_loss: 0.1407 - val_acc: 0.9360\n",
            "Epoch 213/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1422 - acc: 0.9370 - val_loss: 0.1385 - val_acc: 0.9320\n",
            "Epoch 214/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1460 - acc: 0.9293 - val_loss: 0.1414 - val_acc: 0.9283\n",
            "Epoch 215/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1408 - acc: 0.9360 - val_loss: 0.1348 - val_acc: 0.9330\n",
            "Epoch 216/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1463 - acc: 0.9323 - val_loss: 0.1393 - val_acc: 0.9323\n",
            "Epoch 217/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1422 - acc: 0.9330 - val_loss: 0.1421 - val_acc: 0.9360\n",
            "Epoch 218/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1390 - acc: 0.9373 - val_loss: 0.1351 - val_acc: 0.9303\n",
            "Epoch 219/500\n",
            "3000/3000 [==============================] - 0s 56us/step - loss: 0.1402 - acc: 0.9360 - val_loss: 0.1343 - val_acc: 0.9357\n",
            "Epoch 220/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1406 - acc: 0.9377 - val_loss: 0.1438 - val_acc: 0.9297\n",
            "Epoch 221/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1439 - acc: 0.9330 - val_loss: 0.1402 - val_acc: 0.9360\n",
            "Epoch 222/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1444 - acc: 0.9343 - val_loss: 0.1543 - val_acc: 0.9280\n",
            "Epoch 223/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1375 - acc: 0.9367 - val_loss: 0.1381 - val_acc: 0.9323\n",
            "Epoch 224/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1420 - acc: 0.9277 - val_loss: 0.1343 - val_acc: 0.9310\n",
            "Epoch 225/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1382 - acc: 0.9363 - val_loss: 0.1346 - val_acc: 0.9313\n",
            "Epoch 226/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1410 - acc: 0.9330 - val_loss: 0.1454 - val_acc: 0.9383\n",
            "Epoch 227/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1391 - acc: 0.9367 - val_loss: 0.1325 - val_acc: 0.9373\n",
            "Epoch 228/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1412 - acc: 0.9353 - val_loss: 0.1375 - val_acc: 0.9360\n",
            "Epoch 229/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1382 - acc: 0.9373 - val_loss: 0.1380 - val_acc: 0.9283\n",
            "Epoch 230/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1407 - acc: 0.9383 - val_loss: 0.1453 - val_acc: 0.9263\n",
            "Epoch 231/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1425 - acc: 0.9363 - val_loss: 0.1577 - val_acc: 0.9277\n",
            "Epoch 232/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1372 - acc: 0.9337 - val_loss: 0.1372 - val_acc: 0.9290\n",
            "Epoch 233/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1414 - acc: 0.9323 - val_loss: 0.1397 - val_acc: 0.9337\n",
            "Epoch 234/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1401 - acc: 0.9347 - val_loss: 0.1334 - val_acc: 0.9290\n",
            "Epoch 235/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1402 - acc: 0.9343 - val_loss: 0.1422 - val_acc: 0.9347\n",
            "Epoch 236/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1376 - acc: 0.9360 - val_loss: 0.1377 - val_acc: 0.9327\n",
            "Epoch 237/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1414 - acc: 0.9353 - val_loss: 0.1350 - val_acc: 0.9377\n",
            "Epoch 238/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1426 - acc: 0.9347 - val_loss: 0.1336 - val_acc: 0.9297\n",
            "Epoch 239/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1399 - acc: 0.9343 - val_loss: 0.1349 - val_acc: 0.9323\n",
            "Epoch 240/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1377 - acc: 0.9347 - val_loss: 0.1357 - val_acc: 0.9337\n",
            "Epoch 241/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1414 - acc: 0.9337 - val_loss: 0.1445 - val_acc: 0.9347\n",
            "Epoch 242/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1410 - acc: 0.9360 - val_loss: 0.1363 - val_acc: 0.9373\n",
            "Epoch 243/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1423 - acc: 0.9313 - val_loss: 0.1481 - val_acc: 0.9347\n",
            "Epoch 244/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1409 - acc: 0.9387 - val_loss: 0.1354 - val_acc: 0.9327\n",
            "Epoch 245/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1436 - acc: 0.9357 - val_loss: 0.1334 - val_acc: 0.9330\n",
            "Epoch 246/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1389 - acc: 0.9347 - val_loss: 0.1428 - val_acc: 0.9373\n",
            "Epoch 247/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1399 - acc: 0.9337 - val_loss: 0.1369 - val_acc: 0.9380\n",
            "Epoch 248/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1396 - acc: 0.9353 - val_loss: 0.1367 - val_acc: 0.9373\n",
            "Epoch 249/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1416 - acc: 0.9327 - val_loss: 0.1352 - val_acc: 0.9367\n",
            "Epoch 250/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1398 - acc: 0.9333 - val_loss: 0.1350 - val_acc: 0.9333\n",
            "Epoch 251/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1381 - acc: 0.9383 - val_loss: 0.1409 - val_acc: 0.9357\n",
            "Epoch 252/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1357 - acc: 0.9393 - val_loss: 0.1367 - val_acc: 0.9367\n",
            "Epoch 253/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1400 - acc: 0.9377 - val_loss: 0.1339 - val_acc: 0.9317\n",
            "Epoch 254/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1372 - acc: 0.9360 - val_loss: 0.1444 - val_acc: 0.9340\n",
            "Epoch 255/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1369 - acc: 0.9377 - val_loss: 0.1312 - val_acc: 0.9397\n",
            "Epoch 256/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1349 - acc: 0.9357 - val_loss: 0.1308 - val_acc: 0.9340\n",
            "Epoch 257/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1367 - acc: 0.9390 - val_loss: 0.1324 - val_acc: 0.9323\n",
            "Epoch 258/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1362 - acc: 0.9390 - val_loss: 0.1300 - val_acc: 0.9340\n",
            "Epoch 259/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1343 - acc: 0.9363 - val_loss: 0.1380 - val_acc: 0.9310\n",
            "Epoch 260/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1360 - acc: 0.9347 - val_loss: 0.1305 - val_acc: 0.9403\n",
            "Epoch 261/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1377 - acc: 0.9383 - val_loss: 0.1332 - val_acc: 0.9387\n",
            "Epoch 262/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1356 - acc: 0.9357 - val_loss: 0.1391 - val_acc: 0.9377\n",
            "Epoch 263/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1327 - acc: 0.9387 - val_loss: 0.1327 - val_acc: 0.9367\n",
            "Epoch 264/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1348 - acc: 0.9367 - val_loss: 0.1344 - val_acc: 0.9360\n",
            "Epoch 265/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1356 - acc: 0.9373 - val_loss: 0.1267 - val_acc: 0.9397\n",
            "Epoch 266/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1375 - acc: 0.9367 - val_loss: 0.1309 - val_acc: 0.9413\n",
            "Epoch 267/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1408 - acc: 0.9347 - val_loss: 0.1309 - val_acc: 0.9353\n",
            "Epoch 268/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1376 - acc: 0.9350 - val_loss: 0.1349 - val_acc: 0.9403\n",
            "Epoch 269/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1366 - acc: 0.9350 - val_loss: 0.1273 - val_acc: 0.9397\n",
            "Epoch 270/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1382 - acc: 0.9390 - val_loss: 0.1319 - val_acc: 0.9413\n",
            "Epoch 271/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1362 - acc: 0.9400 - val_loss: 0.1361 - val_acc: 0.9407\n",
            "Epoch 272/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1366 - acc: 0.9367 - val_loss: 0.1406 - val_acc: 0.9293\n",
            "Epoch 273/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1391 - acc: 0.9347 - val_loss: 0.1289 - val_acc: 0.9357\n",
            "Epoch 274/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1338 - acc: 0.9383 - val_loss: 0.1304 - val_acc: 0.9353\n",
            "Epoch 275/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1395 - acc: 0.9347 - val_loss: 0.1570 - val_acc: 0.9317\n",
            "Epoch 276/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1360 - acc: 0.9377 - val_loss: 0.1366 - val_acc: 0.9307\n",
            "Epoch 277/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1341 - acc: 0.9390 - val_loss: 0.1337 - val_acc: 0.9373\n",
            "Epoch 278/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1362 - acc: 0.9347 - val_loss: 0.1266 - val_acc: 0.9393\n",
            "Epoch 279/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1332 - acc: 0.9353 - val_loss: 0.1287 - val_acc: 0.9347\n",
            "Epoch 280/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1350 - acc: 0.9393 - val_loss: 0.1263 - val_acc: 0.9360\n",
            "Epoch 281/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1389 - acc: 0.9360 - val_loss: 0.1374 - val_acc: 0.9337\n",
            "Epoch 282/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1329 - acc: 0.9400 - val_loss: 0.1274 - val_acc: 0.9413\n",
            "Epoch 283/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1317 - acc: 0.9417 - val_loss: 0.1309 - val_acc: 0.9343\n",
            "Epoch 284/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1378 - acc: 0.9390 - val_loss: 0.1271 - val_acc: 0.9387\n",
            "Epoch 285/500\n",
            "3000/3000 [==============================] - 0s 55us/step - loss: 0.1337 - acc: 0.9417 - val_loss: 0.1319 - val_acc: 0.9390\n",
            "Epoch 286/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1362 - acc: 0.9380 - val_loss: 0.1408 - val_acc: 0.9377\n",
            "Epoch 287/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1319 - acc: 0.9397 - val_loss: 0.1316 - val_acc: 0.9357\n",
            "Epoch 288/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1331 - acc: 0.9330 - val_loss: 0.1302 - val_acc: 0.9397\n",
            "Epoch 289/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1339 - acc: 0.9353 - val_loss: 0.1304 - val_acc: 0.9357\n",
            "Epoch 290/500\n",
            "3000/3000 [==============================] - 0s 55us/step - loss: 0.1319 - acc: 0.9397 - val_loss: 0.1319 - val_acc: 0.9323\n",
            "Epoch 291/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1341 - acc: 0.9380 - val_loss: 0.1376 - val_acc: 0.9363\n",
            "Epoch 292/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1331 - acc: 0.9383 - val_loss: 0.1344 - val_acc: 0.9327\n",
            "Epoch 293/500\n",
            "3000/3000 [==============================] - 0s 56us/step - loss: 0.1319 - acc: 0.9390 - val_loss: 0.1337 - val_acc: 0.9380\n",
            "Epoch 294/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1352 - acc: 0.9370 - val_loss: 0.1313 - val_acc: 0.9410\n",
            "Epoch 295/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1411 - acc: 0.9337 - val_loss: 0.1563 - val_acc: 0.9243\n",
            "Epoch 296/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1328 - acc: 0.9390 - val_loss: 0.1374 - val_acc: 0.9317\n",
            "Epoch 297/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1325 - acc: 0.9370 - val_loss: 0.1309 - val_acc: 0.9350\n",
            "Epoch 298/500\n",
            "3000/3000 [==============================] - 0s 56us/step - loss: 0.1329 - acc: 0.9383 - val_loss: 0.1255 - val_acc: 0.9443\n",
            "Epoch 299/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1344 - acc: 0.9380 - val_loss: 0.1310 - val_acc: 0.9440\n",
            "Epoch 300/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1332 - acc: 0.9390 - val_loss: 0.1335 - val_acc: 0.9387\n",
            "Epoch 301/500\n",
            "3000/3000 [==============================] - 0s 55us/step - loss: 0.1349 - acc: 0.9383 - val_loss: 0.1287 - val_acc: 0.9403\n",
            "Epoch 302/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1310 - acc: 0.9380 - val_loss: 0.1321 - val_acc: 0.9380\n",
            "Epoch 303/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1360 - acc: 0.9370 - val_loss: 0.1487 - val_acc: 0.9283\n",
            "Epoch 304/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1303 - acc: 0.9370 - val_loss: 0.1404 - val_acc: 0.9340\n",
            "Epoch 305/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1297 - acc: 0.9410 - val_loss: 0.1253 - val_acc: 0.9403\n",
            "Epoch 306/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1291 - acc: 0.9410 - val_loss: 0.1285 - val_acc: 0.9403\n",
            "Epoch 307/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1330 - acc: 0.9367 - val_loss: 0.1288 - val_acc: 0.9403\n",
            "Epoch 308/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1337 - acc: 0.9360 - val_loss: 0.1374 - val_acc: 0.9413\n",
            "Epoch 309/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1337 - acc: 0.9377 - val_loss: 0.1292 - val_acc: 0.9367\n",
            "Epoch 310/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1313 - acc: 0.9363 - val_loss: 0.1518 - val_acc: 0.9330\n",
            "Epoch 311/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1370 - acc: 0.9383 - val_loss: 0.1313 - val_acc: 0.9313\n",
            "Epoch 312/500\n",
            "3000/3000 [==============================] - 0s 55us/step - loss: 0.1355 - acc: 0.9353 - val_loss: 0.1272 - val_acc: 0.9357\n",
            "Epoch 313/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1290 - acc: 0.9427 - val_loss: 0.1325 - val_acc: 0.9327\n",
            "Epoch 314/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1310 - acc: 0.9390 - val_loss: 0.1260 - val_acc: 0.9337\n",
            "Epoch 315/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1286 - acc: 0.9383 - val_loss: 0.1238 - val_acc: 0.9400\n",
            "Epoch 316/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1283 - acc: 0.9390 - val_loss: 0.1391 - val_acc: 0.9340\n",
            "Epoch 317/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1280 - acc: 0.9387 - val_loss: 0.1322 - val_acc: 0.9353\n",
            "Epoch 318/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1322 - acc: 0.9393 - val_loss: 0.1260 - val_acc: 0.9383\n",
            "Epoch 319/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1303 - acc: 0.9413 - val_loss: 0.1314 - val_acc: 0.9370\n",
            "Epoch 320/500\n",
            "3000/3000 [==============================] - 0s 55us/step - loss: 0.1303 - acc: 0.9363 - val_loss: 0.1227 - val_acc: 0.9377\n",
            "Epoch 321/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1291 - acc: 0.9357 - val_loss: 0.1242 - val_acc: 0.9400\n",
            "Epoch 322/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1309 - acc: 0.9360 - val_loss: 0.1259 - val_acc: 0.9417\n",
            "Epoch 323/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1294 - acc: 0.9387 - val_loss: 0.1206 - val_acc: 0.9480\n",
            "Epoch 324/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1343 - acc: 0.9400 - val_loss: 0.1413 - val_acc: 0.9383\n",
            "Epoch 325/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1267 - acc: 0.9400 - val_loss: 0.1310 - val_acc: 0.9383\n",
            "Epoch 326/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1309 - acc: 0.9380 - val_loss: 0.1260 - val_acc: 0.9400\n",
            "Epoch 327/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1285 - acc: 0.9420 - val_loss: 0.1313 - val_acc: 0.9380\n",
            "Epoch 328/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1316 - acc: 0.9377 - val_loss: 0.1264 - val_acc: 0.9397\n",
            "Epoch 329/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1289 - acc: 0.9377 - val_loss: 0.1270 - val_acc: 0.9393\n",
            "Epoch 330/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1316 - acc: 0.9393 - val_loss: 0.1447 - val_acc: 0.9357\n",
            "Epoch 331/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1281 - acc: 0.9403 - val_loss: 0.1238 - val_acc: 0.9397\n",
            "Epoch 332/500\n",
            "3000/3000 [==============================] - 0s 57us/step - loss: 0.1315 - acc: 0.9393 - val_loss: 0.1243 - val_acc: 0.9377\n",
            "Epoch 333/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1280 - acc: 0.9400 - val_loss: 0.1260 - val_acc: 0.9370\n",
            "Epoch 334/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1275 - acc: 0.9410 - val_loss: 0.1259 - val_acc: 0.9380\n",
            "Epoch 335/500\n",
            "3000/3000 [==============================] - 0s 55us/step - loss: 0.1271 - acc: 0.9397 - val_loss: 0.1224 - val_acc: 0.9410\n",
            "Epoch 336/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1336 - acc: 0.9343 - val_loss: 0.1277 - val_acc: 0.9390\n",
            "Epoch 337/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1285 - acc: 0.9417 - val_loss: 0.1239 - val_acc: 0.9420\n",
            "Epoch 338/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1279 - acc: 0.9373 - val_loss: 0.1376 - val_acc: 0.9400\n",
            "Epoch 339/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1324 - acc: 0.9403 - val_loss: 0.1266 - val_acc: 0.9410\n",
            "Epoch 340/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1327 - acc: 0.9390 - val_loss: 0.1302 - val_acc: 0.9373\n",
            "Epoch 341/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1277 - acc: 0.9423 - val_loss: 0.1249 - val_acc: 0.9410\n",
            "Epoch 342/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1313 - acc: 0.9373 - val_loss: 0.1244 - val_acc: 0.9367\n",
            "Epoch 343/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1277 - acc: 0.9383 - val_loss: 0.1272 - val_acc: 0.9423\n",
            "Epoch 344/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1262 - acc: 0.9393 - val_loss: 0.1366 - val_acc: 0.9333\n",
            "Epoch 345/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1290 - acc: 0.9427 - val_loss: 0.1345 - val_acc: 0.9390\n",
            "Epoch 346/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1285 - acc: 0.9380 - val_loss: 0.1258 - val_acc: 0.9350\n",
            "Epoch 347/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1293 - acc: 0.9367 - val_loss: 0.1297 - val_acc: 0.9393\n",
            "Epoch 348/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1310 - acc: 0.9393 - val_loss: 0.1269 - val_acc: 0.9397\n",
            "Epoch 349/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1289 - acc: 0.9403 - val_loss: 0.1337 - val_acc: 0.9360\n",
            "Epoch 350/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1266 - acc: 0.9420 - val_loss: 0.1324 - val_acc: 0.9407\n",
            "Epoch 351/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1265 - acc: 0.9403 - val_loss: 0.1250 - val_acc: 0.9390\n",
            "Epoch 352/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1284 - acc: 0.9363 - val_loss: 0.1246 - val_acc: 0.9400\n",
            "Epoch 353/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1281 - acc: 0.9390 - val_loss: 0.1272 - val_acc: 0.9407\n",
            "Epoch 354/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1313 - acc: 0.9407 - val_loss: 0.1235 - val_acc: 0.9467\n",
            "Epoch 355/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1277 - acc: 0.9390 - val_loss: 0.1240 - val_acc: 0.9407\n",
            "Epoch 356/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1296 - acc: 0.9383 - val_loss: 0.1380 - val_acc: 0.9383\n",
            "Epoch 357/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1282 - acc: 0.9420 - val_loss: 0.1227 - val_acc: 0.9397\n",
            "Epoch 358/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1243 - acc: 0.9433 - val_loss: 0.1300 - val_acc: 0.9343\n",
            "Epoch 359/500\n",
            "3000/3000 [==============================] - 0s 55us/step - loss: 0.1253 - acc: 0.9397 - val_loss: 0.1308 - val_acc: 0.9380\n",
            "Epoch 360/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1260 - acc: 0.9413 - val_loss: 0.1318 - val_acc: 0.9363\n",
            "Epoch 361/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1276 - acc: 0.9370 - val_loss: 0.1377 - val_acc: 0.9370\n",
            "Epoch 362/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1289 - acc: 0.9393 - val_loss: 0.1206 - val_acc: 0.9370\n",
            "Epoch 363/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1251 - acc: 0.9413 - val_loss: 0.1227 - val_acc: 0.9407\n",
            "Epoch 364/500\n",
            "3000/3000 [==============================] - 0s 55us/step - loss: 0.1280 - acc: 0.9397 - val_loss: 0.1225 - val_acc: 0.9470\n",
            "Epoch 365/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1263 - acc: 0.9400 - val_loss: 0.1231 - val_acc: 0.9380\n",
            "Epoch 366/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1255 - acc: 0.9413 - val_loss: 0.1363 - val_acc: 0.9360\n",
            "Epoch 367/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1289 - acc: 0.9393 - val_loss: 0.1261 - val_acc: 0.9380\n",
            "Epoch 368/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1258 - acc: 0.9397 - val_loss: 0.1501 - val_acc: 0.9227\n",
            "Epoch 369/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1265 - acc: 0.9400 - val_loss: 0.1306 - val_acc: 0.9327\n",
            "Epoch 370/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1267 - acc: 0.9450 - val_loss: 0.1310 - val_acc: 0.9400\n",
            "Epoch 371/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1262 - acc: 0.9423 - val_loss: 0.1160 - val_acc: 0.9467\n",
            "Epoch 372/500\n",
            "3000/3000 [==============================] - 0s 56us/step - loss: 0.1298 - acc: 0.9387 - val_loss: 0.1240 - val_acc: 0.9400\n",
            "Epoch 373/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1251 - acc: 0.9410 - val_loss: 0.1346 - val_acc: 0.9343\n",
            "Epoch 374/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1251 - acc: 0.9393 - val_loss: 0.1208 - val_acc: 0.9423\n",
            "Epoch 375/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1265 - acc: 0.9363 - val_loss: 0.1433 - val_acc: 0.9363\n",
            "Epoch 376/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1243 - acc: 0.9400 - val_loss: 0.1534 - val_acc: 0.9310\n",
            "Epoch 377/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1301 - acc: 0.9380 - val_loss: 0.1231 - val_acc: 0.9477\n",
            "Epoch 378/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1281 - acc: 0.9393 - val_loss: 0.1272 - val_acc: 0.9423\n",
            "Epoch 379/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1257 - acc: 0.9397 - val_loss: 0.1312 - val_acc: 0.9370\n",
            "Epoch 380/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1248 - acc: 0.9357 - val_loss: 0.1181 - val_acc: 0.9413\n",
            "Epoch 381/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1235 - acc: 0.9407 - val_loss: 0.1268 - val_acc: 0.9440\n",
            "Epoch 382/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1256 - acc: 0.9393 - val_loss: 0.1405 - val_acc: 0.9387\n",
            "Epoch 383/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1252 - acc: 0.9430 - val_loss: 0.1206 - val_acc: 0.9447\n",
            "Epoch 384/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1278 - acc: 0.9423 - val_loss: 0.1315 - val_acc: 0.9397\n",
            "Epoch 385/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1275 - acc: 0.9427 - val_loss: 0.1264 - val_acc: 0.9390\n",
            "Epoch 386/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1251 - acc: 0.9397 - val_loss: 0.1206 - val_acc: 0.9397\n",
            "Epoch 387/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1254 - acc: 0.9387 - val_loss: 0.1211 - val_acc: 0.9437\n",
            "Epoch 388/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1219 - acc: 0.9427 - val_loss: 0.1275 - val_acc: 0.9407\n",
            "Epoch 389/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1301 - acc: 0.9373 - val_loss: 0.1234 - val_acc: 0.9390\n",
            "Epoch 390/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1255 - acc: 0.9393 - val_loss: 0.1217 - val_acc: 0.9437\n",
            "Epoch 391/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1224 - acc: 0.9423 - val_loss: 0.1187 - val_acc: 0.9437\n",
            "Epoch 392/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1240 - acc: 0.9420 - val_loss: 0.1223 - val_acc: 0.9400\n",
            "Epoch 393/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1245 - acc: 0.9430 - val_loss: 0.1274 - val_acc: 0.9403\n",
            "Epoch 394/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1272 - acc: 0.9400 - val_loss: 0.1229 - val_acc: 0.9403\n",
            "Epoch 395/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1257 - acc: 0.9410 - val_loss: 0.1291 - val_acc: 0.9390\n",
            "Epoch 396/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1229 - acc: 0.9430 - val_loss: 0.1177 - val_acc: 0.9420\n",
            "Epoch 397/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1243 - acc: 0.9397 - val_loss: 0.1179 - val_acc: 0.9447\n",
            "Epoch 398/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1262 - acc: 0.9417 - val_loss: 0.1257 - val_acc: 0.9377\n",
            "Epoch 399/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1254 - acc: 0.9420 - val_loss: 0.1212 - val_acc: 0.9410\n",
            "Epoch 400/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1237 - acc: 0.9440 - val_loss: 0.1165 - val_acc: 0.9453\n",
            "Epoch 401/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1218 - acc: 0.9430 - val_loss: 0.1256 - val_acc: 0.9357\n",
            "Epoch 402/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1255 - acc: 0.9417 - val_loss: 0.1264 - val_acc: 0.9343\n",
            "Epoch 403/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1213 - acc: 0.9423 - val_loss: 0.1200 - val_acc: 0.9420\n",
            "Epoch 404/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1283 - acc: 0.9400 - val_loss: 0.1290 - val_acc: 0.9363\n",
            "Epoch 405/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1260 - acc: 0.9423 - val_loss: 0.1213 - val_acc: 0.9400\n",
            "Epoch 406/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1225 - acc: 0.9410 - val_loss: 0.1190 - val_acc: 0.9463\n",
            "Epoch 407/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1228 - acc: 0.9433 - val_loss: 0.1233 - val_acc: 0.9433\n",
            "Epoch 408/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1224 - acc: 0.9443 - val_loss: 0.1266 - val_acc: 0.9407\n",
            "Epoch 409/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1222 - acc: 0.9407 - val_loss: 0.1170 - val_acc: 0.9457\n",
            "Epoch 410/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1260 - acc: 0.9397 - val_loss: 0.1440 - val_acc: 0.9290\n",
            "Epoch 411/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1207 - acc: 0.9447 - val_loss: 0.1206 - val_acc: 0.9400\n",
            "Epoch 412/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1203 - acc: 0.9373 - val_loss: 0.1226 - val_acc: 0.9373\n",
            "Epoch 413/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1211 - acc: 0.9440 - val_loss: 0.1188 - val_acc: 0.9423\n",
            "Epoch 414/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1264 - acc: 0.9417 - val_loss: 0.1314 - val_acc: 0.9323\n",
            "Epoch 415/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1254 - acc: 0.9417 - val_loss: 0.1237 - val_acc: 0.9407\n",
            "Epoch 416/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1199 - acc: 0.9410 - val_loss: 0.1146 - val_acc: 0.9457\n",
            "Epoch 417/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1233 - acc: 0.9403 - val_loss: 0.1355 - val_acc: 0.9397\n",
            "Epoch 418/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1236 - acc: 0.9383 - val_loss: 0.1242 - val_acc: 0.9357\n",
            "Epoch 419/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1222 - acc: 0.9413 - val_loss: 0.1202 - val_acc: 0.9413\n",
            "Epoch 420/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1281 - acc: 0.9387 - val_loss: 0.1263 - val_acc: 0.9393\n",
            "Epoch 421/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1245 - acc: 0.9410 - val_loss: 0.1182 - val_acc: 0.9427\n",
            "Epoch 422/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1213 - acc: 0.9420 - val_loss: 0.1233 - val_acc: 0.9467\n",
            "Epoch 423/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1190 - acc: 0.9453 - val_loss: 0.1245 - val_acc: 0.9340\n",
            "Epoch 424/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1213 - acc: 0.9393 - val_loss: 0.1183 - val_acc: 0.9447\n",
            "Epoch 425/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1201 - acc: 0.9427 - val_loss: 0.1187 - val_acc: 0.9460\n",
            "Epoch 426/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1217 - acc: 0.9380 - val_loss: 0.1181 - val_acc: 0.9410\n",
            "Epoch 427/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1200 - acc: 0.9427 - val_loss: 0.1160 - val_acc: 0.9470\n",
            "Epoch 428/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1245 - acc: 0.9417 - val_loss: 0.1170 - val_acc: 0.9440\n",
            "Epoch 429/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1194 - acc: 0.9430 - val_loss: 0.1317 - val_acc: 0.9403\n",
            "Epoch 430/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1230 - acc: 0.9410 - val_loss: 0.1171 - val_acc: 0.9423\n",
            "Epoch 431/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1175 - acc: 0.9457 - val_loss: 0.1279 - val_acc: 0.9413\n",
            "Epoch 432/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1231 - acc: 0.9433 - val_loss: 0.1177 - val_acc: 0.9443\n",
            "Epoch 433/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1209 - acc: 0.9427 - val_loss: 0.1171 - val_acc: 0.9460\n",
            "Epoch 434/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1271 - acc: 0.9400 - val_loss: 0.1224 - val_acc: 0.9420\n",
            "Epoch 435/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1240 - acc: 0.9380 - val_loss: 0.1256 - val_acc: 0.9410\n",
            "Epoch 436/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1233 - acc: 0.9400 - val_loss: 0.1251 - val_acc: 0.9423\n",
            "Epoch 437/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1209 - acc: 0.9423 - val_loss: 0.1160 - val_acc: 0.9407\n",
            "Epoch 438/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1218 - acc: 0.9423 - val_loss: 0.1169 - val_acc: 0.9450\n",
            "Epoch 439/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1184 - acc: 0.9413 - val_loss: 0.1165 - val_acc: 0.9423\n",
            "Epoch 440/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1222 - acc: 0.9393 - val_loss: 0.1164 - val_acc: 0.9430\n",
            "Epoch 441/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1202 - acc: 0.9427 - val_loss: 0.1223 - val_acc: 0.9387\n",
            "Epoch 442/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1203 - acc: 0.9413 - val_loss: 0.1217 - val_acc: 0.9437\n",
            "Epoch 443/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1227 - acc: 0.9383 - val_loss: 0.1159 - val_acc: 0.9500\n",
            "Epoch 444/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1194 - acc: 0.9447 - val_loss: 0.1358 - val_acc: 0.9413\n",
            "Epoch 445/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1238 - acc: 0.9433 - val_loss: 0.1282 - val_acc: 0.9360\n",
            "Epoch 446/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1228 - acc: 0.9407 - val_loss: 0.1195 - val_acc: 0.9420\n",
            "Epoch 447/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1192 - acc: 0.9427 - val_loss: 0.1145 - val_acc: 0.9487\n",
            "Epoch 448/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1223 - acc: 0.9387 - val_loss: 0.1227 - val_acc: 0.9450\n",
            "Epoch 449/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1207 - acc: 0.9427 - val_loss: 0.1161 - val_acc: 0.9473\n",
            "Epoch 450/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1231 - acc: 0.9403 - val_loss: 0.1297 - val_acc: 0.9340\n",
            "Epoch 451/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1211 - acc: 0.9410 - val_loss: 0.1190 - val_acc: 0.9467\n",
            "Epoch 452/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1185 - acc: 0.9443 - val_loss: 0.1138 - val_acc: 0.9477\n",
            "Epoch 453/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1226 - acc: 0.9420 - val_loss: 0.1169 - val_acc: 0.9447\n",
            "Epoch 454/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1196 - acc: 0.9407 - val_loss: 0.1163 - val_acc: 0.9430\n",
            "Epoch 455/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1180 - acc: 0.9433 - val_loss: 0.1191 - val_acc: 0.9450\n",
            "Epoch 456/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1179 - acc: 0.9433 - val_loss: 0.1181 - val_acc: 0.9483\n",
            "Epoch 457/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1256 - acc: 0.9393 - val_loss: 0.1199 - val_acc: 0.9447\n",
            "Epoch 458/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1225 - acc: 0.9420 - val_loss: 0.1229 - val_acc: 0.9380\n",
            "Epoch 459/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1213 - acc: 0.9437 - val_loss: 0.1162 - val_acc: 0.9467\n",
            "Epoch 460/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1222 - acc: 0.9423 - val_loss: 0.1172 - val_acc: 0.9427\n",
            "Epoch 461/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1209 - acc: 0.9447 - val_loss: 0.1188 - val_acc: 0.9460\n",
            "Epoch 462/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1180 - acc: 0.9430 - val_loss: 0.1116 - val_acc: 0.9483\n",
            "Epoch 463/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1268 - acc: 0.9430 - val_loss: 0.1184 - val_acc: 0.9457\n",
            "Epoch 464/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1193 - acc: 0.9440 - val_loss: 0.1192 - val_acc: 0.9410\n",
            "Epoch 465/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1161 - acc: 0.9437 - val_loss: 0.1140 - val_acc: 0.9463\n",
            "Epoch 466/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1194 - acc: 0.9430 - val_loss: 0.1326 - val_acc: 0.9343\n",
            "Epoch 467/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1206 - acc: 0.9450 - val_loss: 0.1146 - val_acc: 0.9510\n",
            "Epoch 468/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1151 - acc: 0.9423 - val_loss: 0.1165 - val_acc: 0.9467\n",
            "Epoch 469/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1187 - acc: 0.9453 - val_loss: 0.1155 - val_acc: 0.9467\n",
            "Epoch 470/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1174 - acc: 0.9433 - val_loss: 0.1172 - val_acc: 0.9417\n",
            "Epoch 471/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1151 - acc: 0.9423 - val_loss: 0.1135 - val_acc: 0.9490\n",
            "Epoch 472/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1204 - acc: 0.9457 - val_loss: 0.1126 - val_acc: 0.9527\n",
            "Epoch 473/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1189 - acc: 0.9447 - val_loss: 0.1173 - val_acc: 0.9420\n",
            "Epoch 474/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1213 - acc: 0.9420 - val_loss: 0.1197 - val_acc: 0.9457\n",
            "Epoch 475/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1172 - acc: 0.9433 - val_loss: 0.1116 - val_acc: 0.9533\n",
            "Epoch 476/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1204 - acc: 0.9450 - val_loss: 0.1721 - val_acc: 0.9200\n",
            "Epoch 477/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1246 - acc: 0.9420 - val_loss: 0.1307 - val_acc: 0.9380\n",
            "Epoch 478/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1169 - acc: 0.9453 - val_loss: 0.1200 - val_acc: 0.9423\n",
            "Epoch 479/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1193 - acc: 0.9427 - val_loss: 0.1147 - val_acc: 0.9483\n",
            "Epoch 480/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1166 - acc: 0.9410 - val_loss: 0.1205 - val_acc: 0.9470\n",
            "Epoch 481/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1200 - acc: 0.9440 - val_loss: 0.1174 - val_acc: 0.9403\n",
            "Epoch 482/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1156 - acc: 0.9427 - val_loss: 0.1136 - val_acc: 0.9473\n",
            "Epoch 483/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1188 - acc: 0.9440 - val_loss: 0.1129 - val_acc: 0.9453\n",
            "Epoch 484/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1258 - acc: 0.9453 - val_loss: 0.1152 - val_acc: 0.9463\n",
            "Epoch 485/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1167 - acc: 0.9440 - val_loss: 0.1094 - val_acc: 0.9487\n",
            "Epoch 486/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1193 - acc: 0.9423 - val_loss: 0.1136 - val_acc: 0.9490\n",
            "Epoch 487/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1178 - acc: 0.9433 - val_loss: 0.1163 - val_acc: 0.9437\n",
            "Epoch 488/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1180 - acc: 0.9427 - val_loss: 0.1195 - val_acc: 0.9420\n",
            "Epoch 489/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1160 - acc: 0.9417 - val_loss: 0.1137 - val_acc: 0.9490\n",
            "Epoch 490/500\n",
            "3000/3000 [==============================] - 0s 54us/step - loss: 0.1216 - acc: 0.9403 - val_loss: 0.1111 - val_acc: 0.9477\n",
            "Epoch 491/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1167 - acc: 0.9453 - val_loss: 0.1124 - val_acc: 0.9467\n",
            "Epoch 492/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1174 - acc: 0.9437 - val_loss: 0.1222 - val_acc: 0.9387\n",
            "Epoch 493/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1167 - acc: 0.9437 - val_loss: 0.1129 - val_acc: 0.9520\n",
            "Epoch 494/500\n",
            "3000/3000 [==============================] - 0s 53us/step - loss: 0.1171 - acc: 0.9447 - val_loss: 0.1116 - val_acc: 0.9483\n",
            "Epoch 495/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1169 - acc: 0.9440 - val_loss: 0.1369 - val_acc: 0.9333\n",
            "Epoch 496/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1234 - acc: 0.9397 - val_loss: 0.1154 - val_acc: 0.9433\n",
            "Epoch 497/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1243 - acc: 0.9463 - val_loss: 0.1492 - val_acc: 0.9407\n",
            "Epoch 498/500\n",
            "3000/3000 [==============================] - 0s 55us/step - loss: 0.1251 - acc: 0.9420 - val_loss: 0.1130 - val_acc: 0.9447\n",
            "Epoch 499/500\n",
            "3000/3000 [==============================] - 0s 52us/step - loss: 0.1180 - acc: 0.9430 - val_loss: 0.1145 - val_acc: 0.9503\n",
            "Epoch 500/500\n",
            "3000/3000 [==============================] - 0s 51us/step - loss: 0.1179 - acc: 0.9447 - val_loss: 0.1115 - val_acc: 0.9463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lu2OdNE5OeXb",
        "outputId": "a7b5f68c-76ee-4a23-e13d-64e5c7fc16c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "print(history.history.keys())\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwgAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qKxqLjPvEqX3",
        "outputId": "7303b714-fa6c-4ca0-ce48-af63ed9464fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "preds=model.predict(data[:,0:3])\n",
        "print(np.hstack( (preds,data[:,3:]) ))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6.76131845e-02 0.00000000e+00]\n",
            " [1.27851963e-05 0.00000000e+00]\n",
            " [1.87309504e-01 0.00000000e+00]\n",
            " ...\n",
            " [9.99996543e-01 1.00000000e+00]\n",
            " [3.27825546e-07 0.00000000e+00]\n",
            " [1.00000000e+00 1.00000000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSgEZ2S4qyKi",
        "colab_type": "code",
        "outputId": "a7013f77-49e6-4c36-abdb-679557a32e82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "plt.hist(preds[(data[:,3:]==0)])\n",
        "plt.hist(preds[(data[:,3:]==1)],alpha=0.8)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swRWRwf7qxuG",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}