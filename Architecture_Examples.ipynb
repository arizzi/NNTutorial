{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Architecture_Examples.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arizzi/NNTutorial/blob/master/Architecture_Examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEZfE2wcx-V6",
        "colab_type": "text"
      },
      "source": [
        "# Notebook 3: architecture examples\n",
        "In this notebook, we will explore a few kinds of network layers\n",
        "- Conv2D\n",
        "- Concatenated DNN+Conv2D\n",
        "- Conv1D\n",
        "- GRU\n",
        "\n",
        "You will then combine these ingredients in a new model (at your wish) and train the model to check performances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf1nPdcdx-V-",
        "colab_type": "code",
        "outputId": "2a9a45d5-b67b-44c2-9f53-1c89fc9b73f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# keras imports\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input, Conv2D, Dropout, Flatten\n",
        "from keras.layers import Concatenate, Reshape, BatchNormalization, Activation\n",
        "from keras.layers import MaxPooling2D, MaxPooling3D\n",
        "from keras.utils import plot_model\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras import metrics\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
        "from keras.regularizers import l1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJTRF4Mhx-WJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qvcyiawax-WV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGdZ09hyx-Wf",
        "colab_type": "text"
      },
      "source": [
        "# Dataset preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXZUGWE7x-Wh",
        "colab_type": "code",
        "outputId": "8b82d6e7-88cf-40b1-de8e-e7d2d4d092a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "if os.path.isfile('jetImage_Merged.h5') :\n",
        "    print (\"File already downloaded\")\n",
        "else:\n",
        "    !wget http://cern.ch/arizzi/jetImage_Merged.h5\n",
        "f = h5py.File(\"jetImage_Merged.h5\")\n",
        "jets = f.get('jets')\n",
        "y = np.array(jets[:,-6:-1])\n",
        "X = np.array(jets[:,:-6])\n",
        "Ximage = np.array(f.get('jetImage'))\n",
        "Xlist = np.array(f.get('jetConstituentList'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File already downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojQRbVjVx-Wo",
        "colab_type": "code",
        "outputId": "816ad3e4-c3a5-4ea4-b2f2-f1a207d7f705",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape, Ximage.shape, Xlist.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((98001, 53), (98001, 25, 25), (98001, 188, 16))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k9jigDBx-Wt",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "Split the dataset as follows:\n",
        "- 2/3 for training\n",
        "- 1/3 for validation \n",
        "\n",
        "This time we do it by hand, after shuffling the dataset (just in case)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Tn-dH6jx-Wu",
        "colab_type": "code",
        "outputId": "21d3f4bb-1658-4b54-83ed-1369c2f7f629",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nSplit = int(2./3.*X.shape[0])\n",
        "permutation = np.random.permutation(X.shape[0])\n",
        "X = X[permutation]\n",
        "y = y[permutation]\n",
        "Ximage = Ximage[permutation]\n",
        "Xlist = Xlist[permutation]\n",
        "X_train = X[:nSplit, :]\n",
        "X_test = X[nSplit:, :]\n",
        "y_train = y[:nSplit, :]\n",
        "y_test = y[nSplit:, :]\n",
        "Ximage_train = Ximage[:nSplit, :, :]\n",
        "Ximage_test = Ximage[nSplit:, :, :]\n",
        "Xlist_train = Xlist[:nSplit, :, :]\n",
        "Xlist_test = Xlist[nSplit:, :, :]\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, Ximage_train.shape, Ximage_test.shape, Xlist_train.shape, Xlist_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(65334, 53) (32667, 53) (65334, 5) (32667, 5) (65334, 25, 25) (32667, 25, 25) (65334, 188, 16) (32667, 188, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ4KFPmBx-Wy",
        "colab_type": "text"
      },
      "source": [
        "# Build a Conv2D model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EGYzCs_x-Wz",
        "colab_type": "text"
      },
      "source": [
        "Some keras magic: add an extra column for the dataset, representing the channel. <br>\n",
        "For instance:\n",
        "- for images in RGB format one would have 3 challels\n",
        "- for ECAL+HCAL one could foresee two channels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHY4q2Mzx-W0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Ximage_train = Ximage_train.reshape((Ximage_train.shape[0], Ximage_train.shape[1], Ximage_train.shape[2], 1))\n",
        "Ximage_test = Ximage_test.reshape((Ximage_test.shape[0], Ximage_test.shape[1], Ximage_test.shape[2], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfdt0_7qx-W3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "n_epochs = 500\n",
        "dropoutRate = 0.25\n",
        "img_rows = Ximage_train.shape[1]\n",
        "img_cols = Ximage_train.shape[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxB_QUdbx-W6",
        "colab_type": "code",
        "outputId": "efaffaeb-b068-490f-ec31-36856ec8a615",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "image_shape = (img_rows,img_cols,1)\n",
        "####\n",
        "inputImage = Input(shape=(image_shape))\n",
        "x = BatchNormalization()(inputImage)\n",
        "x = Conv2D(5, kernel_size=(3,3), data_format=\"channels_last\", strides=(3, 3), \n",
        "               padding=\"same\", input_shape=image_shape)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Dropout(dropoutRate)(x)\n",
        "#\n",
        "x = Conv2D(3, kernel_size=(5,5), data_format=\"channels_last\", strides=(2, 2), \n",
        "               padding=\"same\", input_shape=image_shape,)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Dropout(dropoutRate)(x)\n",
        "#\n",
        "x = Conv2D(2, kernel_size=(7,7), data_format=\"channels_last\", strides=(2, 2), \n",
        "               padding=\"same\", input_shape=image_shape,)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Dropout(dropoutRate)(x)\n",
        "#\n",
        "x = Flatten()(x)\n",
        "#\n",
        "x = Dense(10, activation='relu')(x)\n",
        "x = Dropout(dropoutRate)(x)\n",
        "#\n",
        "output = Dense(5, activation='softmax')(x)\n",
        "####\n",
        "model = Model(inputs=inputImage, outputs=output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oZe1XJhx-W8",
        "colab_type": "code",
        "outputId": "5cb149db-1076-4257-f014-b383cf83c857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 25, 25, 1)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 25, 25, 1)         4         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 9, 9, 5)           50        \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 9, 9, 5)           20        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 9, 9, 5)           0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 9, 9, 5)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 5, 5, 3)           378       \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 5, 5, 3)           12        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 5, 5, 3)           0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 5, 5, 3)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 3, 3, 2)           296       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 3, 3, 2)           8         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 3, 3, 2)           0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 3, 3, 2)           0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 18)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                190       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 55        \n",
            "=================================================================\n",
            "Total params: 1,013\n",
            "Trainable params: 991\n",
            "Non-trainable params: 22\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWOfn1Tax-W_",
        "colab_type": "text"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMIAKMoDx-XA",
        "colab_type": "code",
        "outputId": "8c872c7f-886e-485c-e56b-6dacd4f6e24b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "# train \n",
        "history = model.fit(Ximage_train, y_train, epochs=n_epochs, batch_size=batch_size, verbose = 2,\n",
        "                validation_data=(Ximage_test, y_test),\n",
        "                callbacks = [\n",
        "                EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
        "                ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1),\n",
        "                TerminateOnNaN()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 65334 samples, validate on 32667 samples\n",
            "Epoch 1/500\n",
            " - 14s - loss: 1.5012 - val_loss: 1.3768\n",
            "Epoch 2/500\n",
            " - 12s - loss: 1.4144 - val_loss: 1.3206\n",
            "Epoch 3/500\n",
            " - 12s - loss: 1.3690 - val_loss: 1.3535\n",
            "Epoch 4/500\n",
            " - 12s - loss: 1.3252 - val_loss: 1.2344\n",
            "Epoch 5/500\n",
            " - 12s - loss: 1.2956 - val_loss: 1.2089\n",
            "Epoch 6/500\n",
            " - 12s - loss: 1.2800 - val_loss: 1.3479\n",
            "Epoch 7/500\n",
            " - 12s - loss: 1.2680 - val_loss: 1.2128\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 8/500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "vHpMI1Khx-XD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot training history\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.yscale('log')\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnQOYkGjx-XG",
        "colab_type": "text"
      },
      "source": [
        "# Store model into files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwadkhUMx-XG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = 'Conv2D_Small'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15yCTOnFx-XI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"models/jetTagger_%s.json\" %name, \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"models/jetTagger_%s.h5\" %name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMoFtxOlx-XL",
        "colab_type": "text"
      },
      "source": [
        "# Read model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2973e6px-XL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import model_from_json\n",
        "# load json and create model\n",
        "json_file = open(\"models/jetTagger_%s.json\" %name, 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "model.load_weights(\"models/jetTagger_%s.h5\" %name)\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq3Ft_KDx-XN",
        "colab_type": "text"
      },
      "source": [
        "# Check Performances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vve_T1vNx-XO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = ['j_g', 'j_q', 'j_w', 'j_z', 'j_t']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNtuBp0jx-XQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "predict_test = model.predict(Ximage_test)\n",
        "df = pd.DataFrame()\n",
        "fpr = {}\n",
        "tpr = {}\n",
        "auc1 = {}\n",
        "\n",
        "plt.figure()\n",
        "for i, label in enumerate(labels):\n",
        "        df[label] = y_test[:,i]\n",
        "        df[label + '_pred'] = predict_test[:,i]\n",
        "\n",
        "        fpr[label], tpr[label], threshold = roc_curve(df[label],df[label+'_pred'])\n",
        "\n",
        "        auc1[label] = auc(fpr[label], tpr[label])\n",
        "\n",
        "        plt.plot(tpr[label],fpr[label],label='%s tagger, auc = %.1f%%'%(label,auc1[label]*100.))\n",
        "plt.semilogy()\n",
        "plt.xlabel(\"sig. efficiency\")\n",
        "plt.ylabel(\"bkg. mistag rate\")\n",
        "plt.ylim(0.0001,1)\n",
        "plt.grid(True)\n",
        "plt.legend(loc='lower right')\n",
        "#plt.savefig('%s/ROC.pdf'%(options.outputDir))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvVgLGsQx-XS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kabnH0fax-XW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cnf_matrix = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(predict_test, axis=1))\n",
        "np.set_printoptions(precision=2)\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=labels,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=labels, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwfL8E0Mx-XZ",
        "colab_type": "text"
      },
      "source": [
        "# Exercise:\n",
        "Try to combine a convolutional and a dense NN (to make it short, train for less than 10 epochs)<br> Keep in mind that two 1-D layers can be concatenated doing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Euxmxfqb2cMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#x = Concatenate()([x1,x2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGUakDIHx-Xa",
        "colab_type": "text"
      },
      "source": [
        "and that it is possible to use arrays of input layers when defining the network \n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCJb8K112eWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model = Model(inputs=[input1, input2], outputs=output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yUQiynex-Xc",
        "colab_type": "text"
      },
      "source": [
        "and two datasets when training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Zu1HdIF2gLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.fit([x1_train, x2_train], y_train, epochs=n_epochs, batch_size=batch_size, verbose = 2, validation_data=([x1_test, x2_test], y_test),"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJNmEL8Ux-Xd",
        "colab_type": "text"
      },
      "source": [
        "# Exercise:\n",
        "Do the same using the list-of-particle dataset with a GRU or LSTM taking as input the first 30 particles in the list of 188  (to make it short, train for less than 100 epochs)<br> \n",
        "Keep in mind that the syntax for a GRU layer is"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaRTB8CG2nmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#x = GRU(20, activation='selu', recurrent_activation='hard_sigmoid')(InputLayer)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}