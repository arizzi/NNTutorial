{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook3_Architecture_Examples_WithSolutions.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arizzi/NNTutorial/blob/master/Notebook3_Architecture_Examples_WithSolutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOPjiZ3EmGUH",
        "colab_type": "text"
      },
      "source": [
        "# Notebook 3: architecture examples\n",
        "In this notebook, we will explore a few kinds of network layers\n",
        "- Conv2D\n",
        "- Concatenated DNN+Conv2D\n",
        "- Conv1D\n",
        "- GRU\n",
        "\n",
        "You will then combine these ingredients in a new model (at your wish) and train the model to check performances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdQzAg333lv0",
        "colab_type": "code",
        "outputId": "fda1670b-bbbd-4e49-82b2-82a65a41cdc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "if os.path.isfile('jetImage_Merged.h5') :\n",
        "    print (\"File already downloaded\")\n",
        "else:\n",
        "    !wget http://cern.ch/arizzi/jetImage_Merged.h5\n",
        "    !mkdir models"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File already downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aPWzJjLmGUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keras imports\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input, Conv2D, Dropout, Flatten, GRU\n",
        "from keras.layers import Concatenate, Reshape, BatchNormalization, Activation\n",
        "from keras.layers import MaxPooling2D, MaxPooling3D\n",
        "from keras.utils import plot_model\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras import metrics\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
        "from keras.regularizers import l1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q35i_6semGUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5vvOR93mGUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go1jgC8UmGUR",
        "colab_type": "text"
      },
      "source": [
        "# Dataset preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RdTDUComGUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = h5py.File(\"jetImage_Merged.h5\")\n",
        "jets = f.get('jets')\n",
        "y = np.array(jets[:,-6:-1])\n",
        "X = np.array(jets[:,:-6])\n",
        "Ximage = np.array(f.get('jetImage'))\n",
        "Xlist = np.array(f.get('jetConstituentList'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tb0CmrImGUU",
        "colab_type": "code",
        "outputId": "6b223857-0165-42f4-fe5b-89b94675310a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "X.shape, Ximage.shape, Xlist.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((98001, 53), (98001, 25, 25), (98001, 188, 16))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Td_PokcxmGUY",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "Split the dataset as follows:\n",
        "- 2/3 for training\n",
        "- 1/3 for validation \n",
        "\n",
        "This time we do it by hand, after shuffling the dataset (just in case)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOJchhommGUZ",
        "colab_type": "code",
        "outputId": "6f053cbf-edca-4b3d-a8b6-6746d9e7cc37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "nSplit = int(2./3.*X.shape[0])\n",
        "permutation = np.random.permutation(X.shape[0])\n",
        "X = X[permutation]\n",
        "y = y[permutation]\n",
        "Ximage = Ximage[permutation]\n",
        "Xlist = Xlist[permutation]\n",
        "X_train = X[:nSplit, :]\n",
        "X_test = X[nSplit:, :]\n",
        "y_train = y[:nSplit, :]\n",
        "y_test = y[nSplit:, :]\n",
        "Ximage_train = Ximage[:nSplit, :, :]\n",
        "Ximage_test = Ximage[nSplit:, :, :]\n",
        "Xlist_train = Xlist[:nSplit, :, :]\n",
        "Xlist_test = Xlist[nSplit:, :, :]\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, Ximage_train.shape, Ximage_test.shape, Xlist_train.shape, Xlist_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(65334, 53) (32667, 53) (65334, 5) (32667, 5) (65334, 25, 25) (32667, 25, 25) (65334, 188, 16) (32667, 188, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruaxV7MkmGUd",
        "colab_type": "text"
      },
      "source": [
        "# Build a Conv2D model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0aGNYl0mGUd",
        "colab_type": "text"
      },
      "source": [
        "Some keras magic: add an extra column for the dataset, representing the channel. <br>\n",
        "For instance:\n",
        "- for images in RGB format one would have 3 challels\n",
        "- for ECAL+HCAL one could foresee two channels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1nE9RRFmGUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Ximage_train = Ximage_train.reshape((Ximage_train.shape[0], Ximage_train.shape[1], Ximage_train.shape[2], 1))\n",
        "Ximage_test = Ximage_test.reshape((Ximage_test.shape[0], Ximage_test.shape[1], Ximage_test.shape[2], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufetxb1qmGUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "n_epochs = 500\n",
        "dropoutRate = 0.25\n",
        "img_rows = Ximage_train.shape[1]\n",
        "img_cols = Ximage_train.shape[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6OujY-PmGUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_shape = (img_rows,img_cols,1)\n",
        "####\n",
        "inputImage = Input(shape=(image_shape))\n",
        "x = BatchNormalization()(inputImage)\n",
        "x = Conv2D(5, kernel_size=(3,3), data_format=\"channels_last\", strides=(3, 3), \n",
        "               padding=\"same\", input_shape=image_shape)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Dropout(dropoutRate)(x)\n",
        "#\n",
        "x = Conv2D(3, kernel_size=(5,5), data_format=\"channels_last\", strides=(2, 2), \n",
        "               padding=\"same\", input_shape=image_shape,)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Dropout(dropoutRate)(x)\n",
        "#\n",
        "x = Conv2D(2, kernel_size=(7,7), data_format=\"channels_last\", strides=(2, 2), \n",
        "               padding=\"same\", input_shape=image_shape,)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Dropout(dropoutRate)(x)\n",
        "#\n",
        "x = Flatten()(x)\n",
        "#\n",
        "x = Dense(10, activation='relu')(x)\n",
        "x = Dropout(dropoutRate)(x)\n",
        "#\n",
        "output = Dense(5, activation='softmax')(x)\n",
        "####\n",
        "model = Model(inputs=inputImage, outputs=output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foOMAHdomGUl",
        "colab_type": "code",
        "outputId": "df21dfd5-4df6-491d-9e91-9f03f095f723",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 25, 25, 1)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 25, 25, 1)         4         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 9, 9, 5)           50        \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 9, 9, 5)           20        \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 9, 9, 5)           0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 9, 9, 5)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 5, 5, 3)           378       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 5, 5, 3)           12        \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 5, 5, 3)           0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 5, 5, 3)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 3, 3, 2)           296       \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 3, 3, 2)           8         \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 3, 3, 2)           0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 3, 3, 2)           0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 18)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                190       \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 5)                 55        \n",
            "=================================================================\n",
            "Total params: 1,013\n",
            "Trainable params: 991\n",
            "Non-trainable params: 22\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRg5KPnPmGUp",
        "colab_type": "text"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkvMZKV5mGUp",
        "colab_type": "code",
        "outputId": "f373c62f-b5f9-473e-ff85-e309d782d7e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        }
      },
      "source": [
        "# train \n",
        "history = model.fit(Ximage_train, y_train, epochs=n_epochs, batch_size=batch_size, verbose = 2,\n",
        "                validation_data=(Ximage_test, y_test),\n",
        "                callbacks = [\n",
        "                EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
        "                ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1),\n",
        "                TerminateOnNaN()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 65334 samples, validate on 32667 samples\n",
            "Epoch 1/500\n",
            " - 18s - loss: 1.5487 - val_loss: 1.4080\n",
            "Epoch 2/500\n",
            " - 17s - loss: 1.4499 - val_loss: 1.3626\n",
            "Epoch 3/500\n",
            " - 17s - loss: 1.4028 - val_loss: 1.3173\n",
            "Epoch 4/500\n",
            " - 17s - loss: 1.3695 - val_loss: 1.2585\n",
            "Epoch 5/500\n",
            " - 17s - loss: 1.3493 - val_loss: 1.2576\n",
            "Epoch 6/500\n",
            " - 17s - loss: 1.3261 - val_loss: 1.2172\n",
            "Epoch 7/500\n",
            " - 17s - loss: 1.3079 - val_loss: 1.2295\n",
            "Epoch 8/500\n",
            " - 17s - loss: 1.2981 - val_loss: 1.5120\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 9/500\n",
            " - 17s - loss: 1.2856 - val_loss: 1.2109\n",
            "Epoch 10/500\n",
            " - 17s - loss: 1.2790 - val_loss: 1.1942\n",
            "Epoch 11/500\n",
            " - 17s - loss: 1.2746 - val_loss: 1.1863\n",
            "Epoch 12/500\n",
            " - 17s - loss: 1.2721 - val_loss: 1.1741\n",
            "Epoch 13/500\n",
            " - 17s - loss: 1.2771 - val_loss: 1.1830\n",
            "Epoch 14/500\n",
            " - 17s - loss: 1.2724 - val_loss: 1.1910\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 15/500\n",
            " - 17s - loss: 1.2720 - val_loss: 1.1895\n",
            "Epoch 16/500\n",
            " - 17s - loss: 1.2688 - val_loss: 1.1917\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Epoch 17/500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "yBg8MWvVmGUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot training history\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.yscale('log')\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWfJeqbJmGUw",
        "colab_type": "text"
      },
      "source": [
        "# Store model into files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSQHkt00mGUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = 'Conv2D_Small'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_FKUdTamGUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"models/jetTagger_%s.json\" %name, \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"models/jetTagger_%s.h5\" %name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3s75HbtumGU2",
        "colab_type": "text"
      },
      "source": [
        "# Read model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Krww-fATmGU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import model_from_json\n",
        "# load json and create model\n",
        "json_file = open(\"models/jetTagger_%s.json\" %name, 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "model.load_weights(\"models/jetTagger_%s.h5\" %name)\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDDyaJFHmGU7",
        "colab_type": "text"
      },
      "source": [
        "# Check Performances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-F-XXtImGU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = ['j_g', 'j_q', 'j_w', 'j_z', 'j_t']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbWWD2yDmGVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "predict_test = model.predict(Ximage_test)\n",
        "df = pd.DataFrame()\n",
        "fpr = {}\n",
        "tpr = {}\n",
        "auc1 = {}\n",
        "\n",
        "plt.figure()\n",
        "for i, label in enumerate(labels):\n",
        "        df[label] = y_test[:,i]\n",
        "        df[label + '_pred'] = predict_test[:,i]\n",
        "\n",
        "        fpr[label], tpr[label], threshold = roc_curve(df[label],df[label+'_pred'])\n",
        "\n",
        "        auc1[label] = auc(fpr[label], tpr[label])\n",
        "\n",
        "        plt.plot(tpr[label],fpr[label],label='%s tagger, auc = %.1f%%'%(label,auc1[label]*100.))\n",
        "plt.semilogy()\n",
        "plt.xlabel(\"sig. efficiency\")\n",
        "plt.ylabel(\"bkg. mistag rate\")\n",
        "plt.ylim(0.0001,1)\n",
        "plt.grid(True)\n",
        "plt.legend(loc='lower right')\n",
        "#plt.savefig('%s/ROC.pdf'%(options.outputDir))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdWe7zO9mGVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLsrCQximGVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cnf_matrix = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(predict_test, axis=1))\n",
        "np.set_printoptions(precision=2)\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=labels,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=labels, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTq-doyKmGVJ",
        "colab_type": "text"
      },
      "source": [
        "# Exercise:\n",
        "Try to combine a convolutional and a dense NN (to make it short, train for less than 10 epochs)<br> Keep in mind that two 1-D layers can be concatenated doing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Sq1GBmXmGVK",
        "colab_type": "raw"
      },
      "source": [
        "x = Concatenate()([x1,x2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HGhmBccmGVK",
        "colab_type": "text"
      },
      "source": [
        "and that it is possible to use arrays of input layers when defining the network "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqj22e4-mGVL",
        "colab_type": "raw"
      },
      "source": [
        "model = Model(inputs=[input1, input2], outputs=output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL3_G-U4mGVM",
        "colab_type": "text"
      },
      "source": [
        "and two datasets when training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujml9A-9mGVM",
        "colab_type": "raw"
      },
      "source": [
        "model.fit([x1_train, x2_train], y_train, epochs=n_epochs, batch_size=batch_size, verbose = 2,\n",
        "                validation_data=([x1_test, x2_test], y_test),"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkvMdJAXmGVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Ximage_train = Ximage_train.reshape((Ximage_train.shape[0], Ximage_train.shape[1], Ximage_train.shape[2], 1))\n",
        "Ximage_test = Ximage_test.reshape((Ximage_test.shape[0], Ximage_test.shape[1], Ximage_test.shape[2], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3QrmwrXmGVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "n_epochs = 10\n",
        "dropoutRate = 0.25\n",
        "img_rows = Ximage_train.shape[1]\n",
        "img_cols = Ximage_train.shape[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7-CnUBwmGVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_shape = (img_rows,img_cols,1)\n",
        "####\n",
        "inputImage = Input(shape=(image_shape))\n",
        "xI = BatchNormalization()(inputImage)\n",
        "xI = Conv2D(5, kernel_size=(5,5), data_format=\"channels_last\", strides=(1, 1), \n",
        "               padding=\"same\", input_shape=image_shape)(xI)\n",
        "xI = BatchNormalization()(xI)\n",
        "xI = Activation(\"relu\")(xI)\n",
        "xI = Dropout(dropoutRate)(xI)\n",
        "#\n",
        "xI = Conv2D(3, kernel_size=(3,3), data_format=\"channels_last\", strides=(1, 1), \n",
        "               padding=\"same\", input_shape=image_shape)(xI)\n",
        "xI = BatchNormalization()(xI)\n",
        "xI = Activation(\"relu\")(xI)\n",
        "xI = Dropout(dropoutRate)(xI)\n",
        "#\n",
        "xI = Conv2D(1, kernel_size=(2,2), data_format=\"channels_last\", strides=(3, 3), \n",
        "               padding=\"same\", input_shape=image_shape)(xI)\n",
        "xI = BatchNormalization()(xI)\n",
        "xI = Activation(\"relu\")(xI)\n",
        "xI = Dropout(dropoutRate)(xI)\n",
        "#\n",
        "xI = Flatten()(xI)\n",
        "#\n",
        "inputLayer = Input(shape=(53,))\n",
        "xD = BatchNormalization()(inputLayer)\n",
        "####\n",
        "xD = Dense(10, activation='relu')(xD)\n",
        "xD = Dropout(dropoutRate)(xD)\n",
        "####\n",
        "x = Concatenate()([xI,xD])\n",
        "x = Dense(5, activation='relu')(x)\n",
        "x = Dropout(dropoutRate)(x)\n",
        "#\n",
        "output = Dense(5, activation='softmax')(x)\n",
        "####\n",
        "model = Model(inputs=[inputImage,inputLayer], outputs=output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn5Wlc1pmGVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZXwbttImGVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train \n",
        "history = model.fit([Ximage_train, X_train],y_train, epochs=n_epochs, batch_size=batch_size, verbose = 2,\n",
        "                validation_data=([Ximage_test, X_test], y_test),\n",
        "                callbacks = [\n",
        "                EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
        "                ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1),\n",
        "                TerminateOnNaN()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US5kyC0xmGVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot training history\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.yscale('log')\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNy5m3rCmGVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write model\n",
        "name = 'Conv2D_DNN_Small'\n",
        "model_json = model.to_json()\n",
        "with open(\"models/jetTagger_%s.json\" %name, \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"models/jetTagger_%s.h5\" %name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StdDYwrrmGVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = ['j_g', 'j_q', 'j_w', 'j_z', 'j_t']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yFvb9hrmGVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "predict_test = model.predict([Ximage_test, X_test])\n",
        "df = pd.DataFrame()\n",
        "fpr = {}\n",
        "tpr = {}\n",
        "auc1 = {}\n",
        "\n",
        "plt.figure()\n",
        "for i, label in enumerate(labels):\n",
        "        df[label] = y_test[:,i]\n",
        "        df[label + '_pred'] = predict_test[:,i]\n",
        "\n",
        "        fpr[label], tpr[label], threshold = roc_curve(df[label],df[label+'_pred'])\n",
        "\n",
        "        auc1[label] = auc(fpr[label], tpr[label])\n",
        "\n",
        "        plt.plot(tpr[label],fpr[label],label='%s tagger, auc = %.1f%%'%(label,auc1[label]*100.))\n",
        "plt.semilogy()\n",
        "plt.xlabel(\"sig. efficiency\")\n",
        "plt.ylabel(\"bkg. mistag rate\")\n",
        "plt.ylim(0.0001,1)\n",
        "plt.grid(True)\n",
        "plt.legend(loc='lower right')\n",
        "#plt.savefig('%s/ROC.pdf'%(options.outputDir))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe8QtWofmGVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cnf_matrix = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(predict_test, axis=1))\n",
        "np.set_printoptions(precision=2)\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=labels,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=labels, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws13ob02mGVq",
        "colab_type": "text"
      },
      "source": [
        "# Exercise:\n",
        "Do the same using the list-of-particle dataset with a GRU taking as input the first 30 particles in the list of 188  (to make it short, train for less than 10 epochs)<br> \n",
        "Keep in mind that the syntax for a GRU layer is"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PrKledRmGVr",
        "colab_type": "raw"
      },
      "source": [
        "x = GRU(20, activation='selu', recurrent_activation='hard_sigmoid')(InputLayer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0WeBJ3TmGVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xlist_test_short = Xlist_test[:,:30,:]\n",
        "Xlist_train_short = Xlist_train[:,:30,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKdMcQ3mmGVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####\n",
        "InputLayer = Input(shape=(30,16))\n",
        "x = GRU(20, activation='selu', recurrent_activation='hard_sigmoid', name='gru_selu',)(InputLayer)\n",
        "x = Dense(20, activation='relu', kernel_initializer='lecun_uniform', name='dense_relu')(x)\n",
        "x = Dropout(dropoutRate)(x)\n",
        "outputLayer = Dense(5, activation='softmax', kernel_initializer='lecun_uniform', name = 'output_softmax')(x)\n",
        "####\n",
        "model = Model(inputs=InputLayer, outputs=outputLayer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1egAlROemGVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbP0z3ofmGVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 100\n",
        "# train \n",
        "history = model.fit(Xlist_train_short, y_train, epochs=n_epochs, batch_size=batch_size, verbose = 2,\n",
        "                validation_data=(Xlist_test_short, y_test),\n",
        "                callbacks = [\n",
        "                EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
        "                ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1),\n",
        "                TerminateOnNaN()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axmo1qxnmGV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot training history\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.yscale('log')\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L2jWSbmmGV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write model\n",
        "name = 'GRU_Small'\n",
        "model_json = model.to_json()\n",
        "with open(\"models/jetTagger_%s.json\" %name, \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"models/jetTagger_%s.h5\" %name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcUxRNMKmGV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = ['j_g', 'j_q', 'j_w', 'j_z', 'j_t']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8m9x4aqmGV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "predict_test = model.predict(Xlist_test_short)\n",
        "df = pd.DataFrame()\n",
        "fpr = {}\n",
        "tpr = {}\n",
        "auc1 = {}\n",
        "\n",
        "plt.figure()\n",
        "for i, label in enumerate(labels):\n",
        "        df[label] = y_test[:,i]\n",
        "        df[label + '_pred'] = predict_test[:,i]\n",
        "\n",
        "        fpr[label], tpr[label], threshold = roc_curve(df[label],df[label+'_pred'])\n",
        "\n",
        "        auc1[label] = auc(fpr[label], tpr[label])\n",
        "\n",
        "        plt.plot(tpr[label],fpr[label],label='%s tagger, auc = %.1f%%'%(label,auc1[label]*100.))\n",
        "plt.semilogy()\n",
        "plt.xlabel(\"sig. efficiency\")\n",
        "plt.ylabel(\"bkg. mistag rate\")\n",
        "plt.ylim(0.0001,1)\n",
        "plt.grid(True)\n",
        "plt.legend(loc='lower right')\n",
        "#plt.savefig('%s/ROC.pdf'%(options.outputDir))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH4jHQ52mGWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cnf_matrix = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(predict_test, axis=1))\n",
        "np.set_printoptions(precision=2)\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=labels,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=labels, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyYnQhobmGWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}