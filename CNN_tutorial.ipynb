{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN tutorial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arizzi/NNTutorial/blob/master/CNN_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y8mytY6WVcF",
        "colab_type": "text"
      },
      "source": [
        "#Tutorial on CNN\n",
        "We try to build a DNN that recognize if an image contains a rectangle or a circle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxgS64DmqCrH",
        "colab_type": "text"
      },
      "source": [
        "## Import useful stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jO_-Tguu60O9",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input,Dense,Dropout,Conv2D,MaxPooling2D,Flatten\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "from math import *\n",
        "from matplotlib import pyplot as plt "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JcejQQHu8WQa"
      },
      "source": [
        "## Lets generate some data\n",
        "\n",
        "We now generate ourself some images with a circle or a rectangle, of random color, in a random position\n",
        "\n",
        "### Exercise\n",
        "1. Try adding more classes such e.g. Lines or Ellipses\n",
        "\n",
        "2. Try adding some random noise in the image background"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGItu2U4lVh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "\n",
        "def randomColor():\n",
        "  return (int(np.random.rand()*256),int(np.random.rand()*256),int(np.random.rand()*256))\n",
        "\n",
        "def drawCircle(c,x,y,r):\n",
        "  img = np.zeros((64,64,3), np.uint8)\n",
        "  cv2.circle(img,(x,y),r,c, -1)\n",
        "  return img\n",
        "\n",
        "def genCircle():\n",
        "  return drawCircle(randomColor(),int(np.random.rand()*30)+10,int(np.random.rand()*30)+10,\n",
        "                    int(np.random.rand()*12)+5)\n",
        "\n",
        "def drawRectangle(c,x,y,w,h):\n",
        "  img = np.zeros((64,64,3), np.uint8)\n",
        "  cv2.rectangle(img,(x,y),((x+w),(y+h)), c, -1)\n",
        "  return img\n",
        "\n",
        "def genRectangle():\n",
        "  return drawRectangle(randomColor(),int(np.random.rand()*30)+10,int(np.random.rand()*30)+10,\n",
        "                       int(np.random.rand()*12)+5,int(np.random.rand()*12)+5)\n",
        "\n",
        "\n",
        "nsamples=500\n",
        "rects=np.stack([genRectangle() for x in range(nsamples)])\n",
        "circs=np.stack([genCircle() for x in range(nsamples)])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XArMXTtMW97o",
        "colab_type": "text"
      },
      "source": [
        "Let's show one of the generated image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiUPPdZ6pNsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(rects.shape)\n",
        "plt.imshow(rects[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LeVJ5UFW68Nf",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeU8chiYxtSu",
        "colab_type": "text"
      },
      "source": [
        "We concatenate zeroes and ones as labels and the shuffle with the same permutation both the data and the labels.\n",
        "## Exercise\n",
        "3. If we have more categories (let say N) we should use a categorical label that is a vector of length N with 1 on the category(/ies) the image belong to and 0 in the others. Try to build a categorical label for two categories (e.g. using numpy \"tile\" function to repeat the same raw multiple times )\n",
        "4. Expand the categorical label to  Ellispes or  Lines  and possibly also non exclusive categories such has 2D vs 1D objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MN1px9PfBp9y",
        "colab": {}
      },
      "source": [
        "labels=np.concatenate((np.zeros(rects.shape[0]),np.ones(circs.shape[0])))\n",
        "data=np.concatenate((rects,circs))\n",
        "permutation = np.random.permutation(data.shape[0])\n",
        "data=data[permutation]\n",
        "labels=labels[permutation]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw5_R5APR4N1",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3NibVPZhC3hL"
      },
      "source": [
        "# Let's build a CNN \n",
        "\n",
        "Now we build our first CNN. We have some Conv layers interleaved with MaxPooling\n",
        "\n",
        "Finally we flatten the output of the convolutional stack and appply a Dense FF\n",
        "\n",
        "### MaxPooling\n",
        "![alt text](https://computersciencewiki.org/images/8/8a/MaxpoolSample2.png)\n",
        "\n",
        "### Exercise\n",
        "5. Try adding/removing convolutional layers, change the kernel size.\n",
        "6. Try changing the model to categorical labels, change loss function from binary_crossentropy to categorical_crossentropy, and use softmax activation instead of sigmoid\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJLV4GOu9vGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs=Input(shape=(64,64,3,))\n",
        "hidden=  Conv2D(6,(3,3), activation='relu')(inputs)\n",
        "hidden=  Conv2D(3,(3,3), activation='relu')(hidden)\n",
        "hidden= MaxPooling2D((8,8))(hidden)\n",
        "hidden=  Conv2D(3,(3,3), activation='relu')(hidden)\n",
        "hidden= MaxPooling2D((4,4))(hidden)\n",
        "hidden= Flatten()(hidden)\n",
        "hidden=  Dense(10, activation='relu')(hidden)\n",
        "hidden=  Dense(10, activation='relu')(hidden)\n",
        "hidden=  Dense(10, activation='relu')(hidden)\n",
        "outputs = Dense(1, activation='sigmoid')(hidden)\n",
        "model = Model(input=inputs, output=outputs)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6JmJFU-9vtN",
        "colab_type": "text"
      },
      "source": [
        "And now let's fit it to our data.\n",
        "The sample is automatically split in two so that 50% of it is used for validation and the other half for training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KRMhsQ2nC6oa",
        "colab": {}
      },
      "source": [
        "history=model.fit(data,labels,validation_split=0.5,epochs=25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKGPKoUU0Ou0",
        "colab_type": "text"
      },
      "source": [
        "*history* contains information about the training.  We can now now show the loss vs epoch for both validation and training samples.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lu2OdNE5OeXb",
        "colab": {}
      },
      "source": [
        "print(history.history.keys())\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.show()\n",
        "plt.plot(history.history[\"val_acc\"])\n",
        "plt.plot(history.history[\"acc\"])\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qKxqLjPvEqX3",
        "colab": {}
      },
      "source": [
        "print(model.predict(np.expand_dims(genRectangle(),axis=0) ))\n",
        "print(model.predict(np.expand_dims(genCircle(),axis=0) ))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWGckuGjZRjm",
        "colab_type": "text"
      },
      "source": [
        "Let's try to mix an image with circles and rectangles and see how the network would evaluate it "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej1RCfrcZPLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im=genCircle()\n",
        "print(\"Looks like a\", (\"circle\" if model.predict(np.expand_dims(im,axis=0) )> 0.5 else \"rectangle\"))\n",
        "plt.imshow(im)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Se-3QB9YZuXX",
        "colab_type": "text"
      },
      "source": [
        "The following code can be used to visualize what features the first conv layer is looking at"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSgEZ2S4qyKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# retrieve weights from the second hidden layer\n",
        "filters, biases = model.layers[1].get_weights()\n",
        "# normalize filter values to 0-1 so we can visualize them\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "# plot first few filters\n",
        "n_filters, ix = 6, 1\n",
        "for i in range(n_filters):\n",
        "\t# get the filter\n",
        "\tf = filters[:, :, :, i]\n",
        "\t# plot each channel separately\n",
        "\tfor j in range(3):\n",
        "\t\t# specify subplot and turn of axis\n",
        "\t\tax = plt.subplot(n_filters, 3, ix)\n",
        "\t\tax.set_xticks([])\n",
        "\t\tax.set_yticks([])\n",
        "\t\t# plot filter channel in grayscale\n",
        "\t\tplt.imshow(f[:, :, j], cmap='gray')\n",
        "\t\tix += 1\n",
        "# show the figure\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}